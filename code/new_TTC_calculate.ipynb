{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Îç∞Ïù¥ÌÑ∞ÏÖã Îã§Ïö¥"
      ],
      "metadata": {
        "id": "T34p2ZlPNKdc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nPgi9p01H-ku"
      },
      "outputs": [],
      "source": [
        "!unzip -q \"/content/drive/MyDrive/shared_drive/·Ñé·Ö°·ÑÖ·Ö£·Üº·Ñâ·Ö°·Üº·Ñê·Ö¢·Ñã·Öµ·Ü´·Ñâ·Öµ·Ü®.zip\" -d /content/dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kOGfDhs5iIKi",
        "outputId": "622dace3-f3e4-4f3a-bcf7-e07a9ef4ac23"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.4.2-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.4.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.4.2 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò"
      ],
      "metadata": {
        "id": "O2v2cEy4NNHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "def prepare_yolo_dataset_by_csv(root_path, csv_path, output_path):\n",
        "    # 1. CSV ÌååÏùº ÏùΩÍ∏∞ Î∞è Îß§Ìïë ÏÇ¨Ï†Ñ ÏÉùÏÑ±\n",
        "    # utf-8-sigÎäî ÌååÏùº ÏãúÏûëÏùò BOM(\\ufeff)ÏùÑ Ï†úÍ±∞ÌïòÍ∏∞ ÏúÑÌï®ÏûÖÎãàÎã§.\n",
        "    df = pd.read_csv(csv_path, encoding='utf-8-sig')\n",
        "\n",
        "    # ÌïÑÏöîÌïú Ïª¨ÎüºÎßå Ï∂îÏ∂úÌïòÍ≥† Ïú†Ìö®Ìïú split Í∞íÎßå ÌïÑÌÑ∞ÎßÅ\n",
        "    df = df[['env', 'split']].dropna()\n",
        "    df = df[df['split'].isin(['train', 'val', 'test'])]\n",
        "\n",
        "    # envÎ™ÖÏùÑ keyÎ°ú, split(train/val/test)ÏùÑ valueÎ°ú ÌïòÎäî ÏÇ¨Ï†Ñ ÏÉùÏÑ±\n",
        "    split_map = dict(zip(df['env'], df['split']))\n",
        "    print(f\"‚úÖ CSV Î°úÎìú ÏôÑÎ£å: {len(split_map)}Í∞úÏùò ÌôòÍ≤Ω(env) ÏÑ§Ï†ï ÏùΩÏùå.\")\n",
        "\n",
        "    # 2. Î™®Îì† png ÌååÏùº Ï∞æÍ∏∞\n",
        "    # Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞Ïóê ÎßûÏ∂∞ **/img/*.png Ìå®ÌÑ¥ÏúºÎ°ú Í≤ÄÏÉâ\n",
        "    image_paths = glob.glob(os.path.join(root_path, \"**/img/*.png\"), recursive=True)\n",
        "    print(f\"Ï¥ù {len(image_paths)}Í∞úÏùò Ïù¥ÎØ∏ÏßÄÎ•º Ï∞æÏïòÏäµÎãàÎã§.\")\n",
        "\n",
        "    if len(image_paths) == 0:\n",
        "        print(\"‚ùå Ïù¥ÎØ∏ÏßÄÎ•º Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§. Í≤ΩÎ°úÎ•º ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî.\")\n",
        "        return\n",
        "\n",
        "    # 3. Ìè¥Îçî Íµ¨Ï°∞ ÏÉùÏÑ± (train, val, test)\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        os.makedirs(os.path.join(output_path, split, 'images'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(output_path, split, 'labels'), exist_ok=True)\n",
        "\n",
        "    # 4. Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Î∞è Î≥µÏÇ¨\n",
        "    processed_count = 0\n",
        "    missing_env_count = 0\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        path_parts = img_path.split(os.sep)\n",
        "\n",
        "        # Íµ¨Ï°∞Í∞Ä 'folder/img/file.png' Ïùº Îïå:\n",
        "        # path_parts[-3] = Ìè¥ÎçîÎ™Ö(env)\n",
        "        folder_name = path_parts[-3]\n",
        "        file_name = path_parts[-1]\n",
        "\n",
        "        # CSVÏóê Ï†ïÏùòÎêú split Ï∞æÍ∏∞\n",
        "        target_split = split_map.get(folder_name)\n",
        "\n",
        "        if not target_split:\n",
        "            # CSVÏóê ÏóÜÎäî Ìè¥ÎçîÎäî Í±¥ÎÑàÎúÅÎãàÎã§.\n",
        "            missing_env_count += 1\n",
        "            continue\n",
        "\n",
        "        # ÏÉàÎ°úÏö¥ ÌååÏùºÎ™Ö ÏÉùÏÑ±: ArtHall_000000.png\n",
        "        new_base_name = f\"{folder_name}_{file_name}\"\n",
        "        new_label_name = new_base_name.replace('.png', '.txt')\n",
        "\n",
        "        # ÏõêÎ≥∏ ÎùºÎ≤® Í≤ΩÎ°ú Ï∞æÍ∏∞ (img -> new_txt)\n",
        "        org_label_path = img_path.replace('img', 'new_txt').replace('.png', '.txt')\n",
        "\n",
        "        if not os.path.exists(org_label_path):\n",
        "            continue\n",
        "\n",
        "        # Ïù¥ÎØ∏ÏßÄ Î°úÎìú Î∞è ÌÅ¨Í∏∞ ÌôïÏù∏\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None: continue\n",
        "        h, w, _ = img.shape\n",
        "\n",
        "        yolo_labels = []\n",
        "        with open(org_label_path, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                data = list(map(float, line.split()))\n",
        "                if len(data) < 5: continue\n",
        "\n",
        "                # 0-3: Ï†àÎåÄÏ¢åÌëú(x1, y1, x2, y2), 4: Agent(Class)\n",
        "                x1, y1, x2, y2 = data[0:4]\n",
        "                class_id = int(data[4])\n",
        "\n",
        "                # YOLO Ï†ïÍ∑úÌôî Î≥ÄÌôò\n",
        "                xc = ((x1 + x2) / 2) / w\n",
        "                yc = ((y1 + y2) / 2) / h\n",
        "                nw = (x2 - x1) / w\n",
        "                nh = (y2 - y1) / h\n",
        "\n",
        "                yolo_labels.append(f\"{class_id} {xc:.6f} {yc:.6f} {nw:.6f} {nh:.6f}\")\n",
        "\n",
        "        if yolo_labels:\n",
        "            # 1. Ïù¥ÎØ∏ÏßÄ Î≥µÏÇ¨ (ÏßÄÏ†ïÎêú split Ìè¥ÎçîÎ°ú)\n",
        "            target_img_path = os.path.join(output_path, target_split, 'images', new_base_name)\n",
        "            shutil.copy(img_path, target_img_path)\n",
        "\n",
        "            # 2. YOLO ÎùºÎ≤® Ï†ÄÏû• (ÏßÄÏ†ïÎêú split Ìè¥ÎçîÎ°ú)\n",
        "            target_label_path = os.path.join(output_path, target_split, 'labels', new_label_name)\n",
        "            with open(target_label_path, 'w') as f:\n",
        "                f.write(\"\\n\".join(yolo_labels))\n",
        "\n",
        "            processed_count += 1\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"‚ú® Ï≤òÎ¶¨ ÏôÑÎ£å!\")\n",
        "    print(f\"- ÏÑ±Í≥µÏ†ÅÏúºÎ°ú Î≥ÄÌôòÎêú Ïù¥ÎØ∏ÏßÄ: {processed_count}Ïû•\")\n",
        "    print(f\"- CSVÏóê Ï†ïÏùòÎêòÏßÄ ÏïäÏïÑ Ï†úÏô∏Îêú Ìè¥Îçî: {missing_env_count}Í∞ú\")\n",
        "    print(f\"- Í≤∞Í≥º Ï†ÄÏû•ÏÜå: {os.path.abspath(output_path)}\")\n",
        "\n",
        "# --- Ïã§Ìñâ Î∞©Î≤ï ---\n",
        "# root_path: ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏûàÎäî Í≥≥ (Ïòà: dataset/train)\n",
        "# csv_path: Ï†úÍ≥µÌï¥Ï£ºÏã† csv ÌååÏùº Í≤ΩÎ°ú\n",
        "# output_path: YOLO Ìè¨Îß∑ÏúºÎ°ú Ï†ÄÏû•Îê† Í≤ΩÎ°ú\n",
        "# prepare_yolo_dataset_by_csv('./dataset/train', './split_assignment.csv', './yolo_final_data')"
      ],
      "metadata": {
        "id": "LDkB__oLZ735"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepare_yolo_dataset_by_csv('./dataset/train', './split_assignment.csv', './yolo_final_data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TMIGHHAEZ9AB",
        "outputId": "283df8da-cfff-4374-f1f6-6d4c1b0d1c4b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ CSV Î°úÎìú ÏôÑÎ£å: 165Í∞úÏùò ÌôòÍ≤Ω(env) ÏÑ§Ï†ï ÏùΩÏùå.\n",
            "Ï¥ù 33187Í∞úÏùò Ïù¥ÎØ∏ÏßÄÎ•º Ï∞æÏïòÏäµÎãàÎã§.\n",
            "------------------------------\n",
            "‚ú® Ï≤òÎ¶¨ ÏôÑÎ£å!\n",
            "- ÏÑ±Í≥µÏ†ÅÏúºÎ°ú Î≥ÄÌôòÎêú Ïù¥ÎØ∏ÏßÄ: 33187Ïû•\n",
            "- CSVÏóê Ï†ïÏùòÎêòÏßÄ ÏïäÏïÑ Ï†úÏô∏Îêú Ìè¥Îçî: 0Í∞ú\n",
            "- Í≤∞Í≥º Ï†ÄÏû•ÏÜå: /content/yolo_final_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "def split_dataset_by_csv_raw(root_path, csv_path, output_path):\n",
        "    # 1. CSV ÌååÏùº ÏùΩÍ∏∞ Î∞è Îß§Ìïë ÏÇ¨Ï†Ñ ÏÉùÏÑ±\n",
        "    # utf-8-sigÎäî ÌååÏùº ÏãúÏûëÏùò BOM(\\ufeff)ÏùÑ Ï†úÍ±∞ÌïòÍ∏∞ ÏúÑÌï®ÏûÖÎãàÎã§.\n",
        "    df = pd.read_csv(csv_path, encoding='utf-8-sig')\n",
        "\n",
        "    # ÌïÑÏöîÌïú Ïª¨ÎüºÎßå Ï∂îÏ∂úÌïòÍ≥† Ïú†Ìö®Ìïú split Í∞íÎßå ÌïÑÌÑ∞ÎßÅ\n",
        "    df = df[['env', 'split']].dropna()\n",
        "    df = df[df['split'].isin(['train', 'val', 'test'])]\n",
        "\n",
        "    # envÎ™ÖÏùÑ keyÎ°ú, split(train/val/test)ÏùÑ valueÎ°ú ÌïòÎäî ÏÇ¨Ï†Ñ ÏÉùÏÑ±\n",
        "    split_map = dict(zip(df['env'], df['split']))\n",
        "    print(f\"‚úÖ CSV Î°úÎìú ÏôÑÎ£å: {len(split_map)}Í∞úÏùò ÌôòÍ≤Ω(env) ÏÑ§Ï†ï ÏùΩÏùå.\")\n",
        "\n",
        "    # 2. Î™®Îì† png ÌååÏùº Ï∞æÍ∏∞\n",
        "    image_paths = glob.glob(os.path.join(root_path, \"**/img/*.png\"), recursive=True)\n",
        "    print(f\"Ï¥ù {len(image_paths)}Í∞úÏùò Ïù¥ÎØ∏ÏßÄÎ•º Ï∞æÏïòÏäµÎãàÎã§.\")\n",
        "\n",
        "    if len(image_paths) == 0:\n",
        "        print(\"‚ùå Ïù¥ÎØ∏ÏßÄÎ•º Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§. Í≤ΩÎ°úÎ•º ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî.\")\n",
        "        return\n",
        "\n",
        "    # 3. Ìè¥Îçî Íµ¨Ï°∞ ÏÉùÏÑ± (train/img, train/new_txt Îì±)\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        os.makedirs(os.path.join(output_path, split, 'img'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(output_path, split, 'new_txt'), exist_ok=True)\n",
        "\n",
        "    # 4. Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Î∞è Î≥µÏÇ¨\n",
        "    processed_count = 0\n",
        "    missing_env_count = 0\n",
        "\n",
        "    print(\"üöÄ ÌååÏùº Î≥µÏÇ¨ ÏãúÏûë...\")\n",
        "    for img_path in tqdm(image_paths):\n",
        "        path_parts = img_path.split(os.sep)\n",
        "\n",
        "        # Íµ¨Ï°∞: .../{folder_name}/img/{file_name}.png\n",
        "        folder_name = path_parts[-3]\n",
        "        file_name = path_parts[-1]\n",
        "\n",
        "        # CSVÏóê Ï†ïÏùòÎêú split Ï∞æÍ∏∞\n",
        "        target_split = split_map.get(folder_name)\n",
        "\n",
        "        if not target_split:\n",
        "            missing_env_count += 1\n",
        "            continue\n",
        "\n",
        "        # ÏõêÎ≥∏ ÎùºÎ≤®(txt) Í≤ΩÎ°ú ÌôïÏù∏\n",
        "        # img Ìè¥ÎçîÏùò ÌååÏùºÏùÑ new_txt Ìè¥ÎçîÏùò ÎåÄÏùëÌïòÎäî ÌååÏùºÎ°ú Î≥ÄÍ≤Ω\n",
        "        org_label_path = img_path.replace(f'{os.sep}img{os.sep}', f'{os.sep}new_txt{os.sep}').replace('.png', '.txt')\n",
        "\n",
        "        # ÎùºÎ≤® ÌååÏùºÏù¥ Ï°¥Ïû¨ÌïòÎäî Í≤ΩÏö∞ÏóêÎßå Î≥µÏÇ¨ ÏßÑÌñâ\n",
        "        if os.path.exists(org_label_path):\n",
        "            # ÏÉàÎ°úÏö¥ ÌååÏùºÎ™Ö: ArtHall_000000.png / ArtHall_000000.txt\n",
        "            new_base_name = f\"{folder_name}_{file_name}\"\n",
        "            new_label_name = new_base_name.replace('.png', '.txt')\n",
        "\n",
        "            # ÎåÄÏÉÅ Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
        "            target_img_dir = os.path.join(output_path, target_split, 'img')\n",
        "            target_txt_dir = os.path.join(output_path, target_split, 'new_txt')\n",
        "\n",
        "            # ÌååÏùº Î≥µÏÇ¨ (shutil.copy2Îäî Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ÍπåÏßÄ Î≥¥Ï°¥)\n",
        "            shutil.copy2(img_path, os.path.join(target_img_dir, new_base_name))\n",
        "            shutil.copy2(org_label_path, os.path.join(target_txt_dir, new_label_name))\n",
        "\n",
        "            processed_count += 1\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"‚ú® Ï≤òÎ¶¨ ÏôÑÎ£å!\")\n",
        "    print(f\"- ÏÑ±Í≥µÏ†ÅÏúºÎ°ú Î≥µÏÇ¨Îêú Îç∞Ïù¥ÌÑ∞ Ïåç: {processed_count}Í∞ú\")\n",
        "    print(f\"- CSVÏóê Ï†ïÏùòÎêòÏßÄ ÏïäÏïÑ Ï†úÏô∏Îêú Ìè¥Îçî: {missing_env_count}Í∞ú\")\n",
        "    print(f\"- Í≤∞Í≥º Ï†ÄÏû•ÏÜå: {os.path.abspath(output_path)}\")\n",
        "\n",
        "# --- Ïã§Ìñâ Î∞©Î≤ï ---\n",
        "# root_path: ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ÏÖã (ArtHall, Gapcheon Îì± Ìè¥ÎçîÎì§Ïù¥ Î™®Ïó¨ÏûàÎäî Í≥≥)\n",
        "# csv_path: split_assignment.csv ÌååÏùº Í≤ΩÎ°ú\n",
        "# output_path: ÎÇòÎàÑÏñ¥ÏßÑ Í≤∞Í≥ºÎ¨ºÏù¥ Ï†ÄÏû•Îê† Í≥≥\n",
        "# split_dataset_by_csv_raw('./dataset/train', './split_assignment.csv', './split_raw_data')"
      ],
      "metadata": {
        "id": "P2sn70yhdLN5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset_by_csv_raw('./dataset/train', './split_assignment.csv', './split_raw_data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht09dTKadU_z",
        "outputId": "412c3002-1395-49c0-df65-b01e553c018e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ CSV Î°úÎìú ÏôÑÎ£å: 165Í∞úÏùò ÌôòÍ≤Ω(env) ÏÑ§Ï†ï ÏùΩÏùå.\n",
            "Ï¥ù 33187Í∞úÏùò Ïù¥ÎØ∏ÏßÄÎ•º Ï∞æÏïòÏäµÎãàÎã§.\n",
            "üöÄ ÌååÏùº Î≥µÏÇ¨ ÏãúÏûë...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33187/33187 [05:31<00:00, 100.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "‚ú® Ï≤òÎ¶¨ ÏôÑÎ£å!\n",
            "- ÏÑ±Í≥µÏ†ÅÏúºÎ°ú Î≥µÏÇ¨Îêú Îç∞Ïù¥ÌÑ∞ Ïåç: 33187Í∞ú\n",
            "- CSVÏóê Ï†ïÏùòÎêòÏßÄ ÏïäÏïÑ Ï†úÏô∏Îêú Ìè¥Îçî: 0Í∞ú\n",
            "- Í≤∞Í≥º Ï†ÄÏû•ÏÜå: /content/split_raw_data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Install ---\n",
        "!pip install numpy filterpy scipy imageio tqdm\n",
        "!git clone https://github.com/abewley/sort.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZOXBpFWIn99",
        "outputId": "73676032-4ffd-48e5-e9b4-c260c4325f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Collecting filterpy\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/178.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (2.37.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from filterpy) (3.10.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio) (11.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->filterpy) (1.17.0)\n",
            "Building wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110460 sha256=55879d7b6d824356a3aed1e422ef55e9aa9170740ed272ee862423a37d21ed81\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/bf/4c/b0c3f4798a0166668752312a67118b27a3cd341e13ac0ae6ee\n",
            "Successfully built filterpy\n",
            "Installing collected packages: filterpy\n",
            "Successfully installed filterpy-1.4.5\n",
            "Cloning into 'sort'...\n",
            "remote: Enumerating objects: 208, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 208 (delta 45), reused 40 (delta 40), pack-reused 159 (from 1)\u001b[K\n",
            "Receiving objects: 100% (208/208), 1.20 MiB | 22.84 MiB/s, done.\n",
            "Resolving deltas: 100% (76/76), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/sort_tracker.py\n",
        "# =====================================================\n",
        "# SORT: Simple Online and Realtime Tracking\n",
        "# Source adapted from https://github.com/abewley/sort\n",
        "# =====================================================\n",
        "\n",
        "import numpy as np\n",
        "from filterpy.kalman import KalmanFilter\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "\n",
        "def iou(bb_test, bb_gt):\n",
        "    xx1 = np.maximum(bb_test[0], bb_gt[0])\n",
        "    yy1 = np.maximum(bb_test[1], bb_gt[1])\n",
        "    xx2 = np.minimum(bb_test[2], bb_gt[2])\n",
        "    yy2 = np.minimum(bb_test[3], bb_gt[3])\n",
        "    w = np.maximum(0., xx2 - xx1)\n",
        "    h = np.maximum(0., yy2 - yy1)\n",
        "    wh = w * h\n",
        "    o = wh / (\n",
        "        (bb_test[2] - bb_test[0]) * (bb_test[3] - bb_test[1]) +\n",
        "        (bb_gt[2] - bb_gt[0]) * (bb_gt[3] - bb_gt[1]) - wh\n",
        "    )\n",
        "    return o\n",
        "\n",
        "\n",
        "class KalmanBoxTracker:\n",
        "    count = 0\n",
        "\n",
        "    def __init__(self, bbox):\n",
        "        self.kf = KalmanFilter(dim_x=7, dim_z=4)\n",
        "        self.kf.F = np.array(\n",
        "            [[1,0,0,0,1,0,0],\n",
        "            [0,1,0,0,0,1,0],\n",
        "            [0,0,1,0,0,0,1],\n",
        "            [0,0,0,1,0,0,0],\n",
        "            [0,0,0,0,1,0,0],\n",
        "            [0,0,0,0,0,1,0],\n",
        "            [0,0,0,0,0,0,1]]\n",
        "        )\n",
        "        self.kf.H = np.array([\n",
        "            [1,0,0,0,0,0,0],\n",
        "            [0,1,0,0,0,0,0],\n",
        "            [0,0,1,0,0,0,0],\n",
        "            [0,0,0,1,0,0,0]\n",
        "        ])\n",
        "        self.kf.R[2:,2:] *= 10.\n",
        "        self.kf.P[4:,4:] *= 1000.\n",
        "        self.kf.P *= 10.\n",
        "        self.kf.Q[-1,-1] *= 0.01\n",
        "        self.kf.Q[4:,4:] *= 0.01\n",
        "\n",
        "        self.kf.x[:4] = bbox.reshape((4,1))\n",
        "        self.time_since_update = 0\n",
        "        self.id = KalmanBoxTracker.count\n",
        "        KalmanBoxTracker.count += 1\n",
        "        self.history = []\n",
        "        self.hits = 0\n",
        "        self.hit_streak = 0\n",
        "        self.age = 0\n",
        "\n",
        "    def update(self, bbox):\n",
        "        self.time_since_update = 0\n",
        "        self.history = []\n",
        "        self.hits += 1\n",
        "        self.hit_streak += 1\n",
        "        self.kf.update(bbox.reshape((4,1)))\n",
        "\n",
        "    def predict(self):\n",
        "        if (self.kf.x[6] + self.kf.x[2]) <= 0:\n",
        "            self.kf.x[6] *= 0.0\n",
        "        self.kf.predict()\n",
        "        self.age += 1\n",
        "        if self.time_since_update > 0:\n",
        "            self.hit_streak = 0\n",
        "        self.time_since_update += 1\n",
        "        self.history.append(self.kf.x)\n",
        "        return self.kf.x\n",
        "\n",
        "\n",
        "class Sort:\n",
        "    def __init__(self, max_age=5, min_hits=2, iou_threshold=0.3):\n",
        "        self.max_age = max_age\n",
        "        self.min_hits = min_hits\n",
        "        self.iou_threshold = iou_threshold\n",
        "        self.trackers = []\n",
        "        self.frame_count = 0\n",
        "\n",
        "    def update(self, dets=np.empty((0,4))):\n",
        "        self.frame_count += 1\n",
        "\n",
        "        trks = np.zeros((len(self.trackers), 4))\n",
        "        to_del = []\n",
        "        for t, trk in enumerate(self.trackers):\n",
        "            pos = trk.predict()\n",
        "            trks[t] = pos[:4].reshape((1,4))\n",
        "            if np.any(np.isnan(pos)):\n",
        "                to_del.append(t)\n",
        "        trks = np.ma.compress_rows(np.ma.masked_invalid(trks))\n",
        "        for t in reversed(to_del):\n",
        "            self.trackers.pop(t)\n",
        "\n",
        "        matched, unmatched_dets, unmatched_trks = associate_detections_to_trackers(\n",
        "            dets, trks, self.iou_threshold\n",
        "        )\n",
        "\n",
        "        for m in matched:\n",
        "            self.trackers[m[1]].update(dets[m[0]])\n",
        "\n",
        "        for i in unmatched_dets:\n",
        "            self.trackers.append(KalmanBoxTracker(dets[i]))\n",
        "\n",
        "        ret = []\n",
        "        for trk in self.trackers:\n",
        "            if trk.time_since_update < 1 and (trk.hits >= self.min_hits or self.frame_count <= self.min_hits):\n",
        "                ret.append(np.concatenate((trk.kf.x[:4].reshape((1,4)), [[trk.id]]), axis=1))\n",
        "        return np.concatenate(ret) if len(ret) > 0 else np.empty((0,5))\n",
        "\n",
        "\n",
        "def associate_detections_to_trackers(detections, trackers, iou_threshold):\n",
        "    if len(trackers) == 0:\n",
        "        return np.empty((0,2), dtype=int), np.arange(len(detections)), np.empty((0), dtype=int)\n",
        "\n",
        "    iou_matrix = np.zeros((len(detections), len(trackers)), dtype=np.float32)\n",
        "    for d, det in enumerate(detections):\n",
        "        for t, trk in enumerate(trackers):\n",
        "            iou_matrix[d,t] = iou(det, trk)\n",
        "\n",
        "    matched_indices = linear_sum_assignment(-iou_matrix)\n",
        "    matched_indices = np.array(list(zip(*matched_indices)))\n",
        "\n",
        "    unmatched_detections = []\n",
        "    for d in range(len(detections)):\n",
        "        if d not in matched_indices[:,0]:\n",
        "            unmatched_detections.append(d)\n",
        "\n",
        "    unmatched_trackers = []\n",
        "    for t in range(len(trackers)):\n",
        "        if t not in matched_indices[:,1]:\n",
        "            unmatched_trackers.append(t)\n",
        "\n",
        "    matches = []\n",
        "    for m in matched_indices:\n",
        "        if iou_matrix[m[0], m[1]] < iou_threshold:\n",
        "            unmatched_detections.append(m[0])\n",
        "            unmatched_trackers.append(m[1])\n",
        "        else:\n",
        "            matches.append(m.reshape(1,2))\n",
        "\n",
        "    if len(matches) == 0:\n",
        "        matches = np.empty((0,2), dtype=int)\n",
        "    else:\n",
        "        matches = np.concatenate(matches, axis=0)\n",
        "\n",
        "    return matches, np.array(unmatched_detections), np.array(unmatched_trackers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZchxXTF8Mt_s",
        "outputId": "f76e596c-8659-4c9d-a485-56994c745ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/sort_tracker.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content\")\n",
        "\n",
        "from sort_tracker import Sort\n",
        "\n",
        "tracker = Sort()\n",
        "print(\"SORT import OK\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y46x-abM5QE",
        "outputId": "a42084e0-5aac-4533-d42a-6947a88a6ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SORT import OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import imageio\n",
        "from collections import deque\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "PkPED1XdKA6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### code"
      ],
      "metadata": {
        "id": "5OQ1LFIDNRUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  class IntentAwareRiskManager:\n",
        "    def __init__(self, window_size=5):\n",
        "        self.window_size = window_size\n",
        "        self.history = {}  # {track_id: deque[(cx, cy)]}\n",
        "\n",
        "    def _update_history(self, track_id, center):\n",
        "        if track_id not in self.history:\n",
        "            self.history[track_id] = deque(maxlen=self.window_size)\n",
        "        self.history[track_id].append(center)\n",
        "\n",
        "    def _is_long_static(self, centers, move_thresh=3.0, min_static_frames=6):\n",
        "        if len(centers) < min_static_frames + 1:\n",
        "            return False\n",
        "\n",
        "        diffs = [\n",
        "            np.linalg.norm(np.array(centers[i]) - np.array(centers[i-1]))\n",
        "            for i in range(1, len(centers))\n",
        "        ]\n",
        "        return all(d < move_thresh for d in diffs[-min_static_frames:])\n",
        "\n",
        "    def _compute_2d_traj_metrics(self, centers, fps, img_w, img_h, eps=1e-3):\n",
        "        \"\"\"\n",
        "        return: ttc, v_rel, d_curr\n",
        "        \"\"\"\n",
        "        if len(centers) < 2:\n",
        "            return float('inf'), 0.0, float('inf')\n",
        "\n",
        "        ego = np.array([img_w / 2, img_h])\n",
        "        p_prev = np.array(centers[-2])\n",
        "        p_curr = np.array(centers[-1])\n",
        "\n",
        "        d_prev = np.linalg.norm(p_prev - ego)\n",
        "        d_curr = np.linalg.norm(p_curr - ego)\n",
        "        v_rel = (d_prev - d_curr) * fps  # px/sec\n",
        "\n",
        "        # Ï†ëÍ∑º Ïïà ÌïòÎ©¥ Î¨¥Ìö®\n",
        "        if v_rel < 5.0:\n",
        "            return float('inf'), v_rel, d_curr\n",
        "\n",
        "        # Ïû•Í∏∞ Ï†ïÏßÄ ÌïÑÌÑ∞\n",
        "        if self._is_long_static(centers):\n",
        "            return float('inf'), v_rel, d_curr\n",
        "\n",
        "        ttc = d_curr / max(v_rel, eps)\n",
        "        return ttc, v_rel, d_curr\n",
        "\n",
        "    def calculate_risk(self, track_id, bbox, location, actions, fps, img_w, img_h):\n",
        "        cx = (bbox[0] + bbox[2]) / 2\n",
        "        cy = (bbox[1] + bbox[3]) / 2\n",
        "        self._update_history(track_id, (cx, cy))\n",
        "        centers = self.history[track_id]\n",
        "\n",
        "        # --- Step 1: Physical risk ---\n",
        "        ttc, v_rel, d_curr = self._compute_2d_traj_metrics(\n",
        "            centers, fps, img_w, img_h\n",
        "        )\n",
        "\n",
        "        base_score = 0.0\n",
        "        if ttc < 5.0:\n",
        "            base_score = min(50.0, 50.0 * (3.0 / max(ttc, 0.5)))\n",
        "\n",
        "        # --- Step 2: Semantic reasoning ---\n",
        "        semantic_bonus = 0.0\n",
        "        omega = 1.0\n",
        "        reason = \"Normal\"\n",
        "\n",
        "        # Ignore irrelevant zones\n",
        "        if location in [2, 3, 4]:\n",
        "            return {\n",
        "                \"score\": 0.0,\n",
        "                \"ttc\": \"Safe\",\n",
        "                \"reason\": \"Ignored\",\n",
        "                \"level\": \"SAFE\"\n",
        "            }\n",
        "\n",
        "        HIGH_SPEED = 80.0  # px/sec\n",
        "\n",
        "        # Ego lane\n",
        "        if location == 0:\n",
        "            if ttc < 2.0 and v_rel > HIGH_SPEED:\n",
        "                reason = \"Rapid Approach\"\n",
        "                semantic_bonus = 10.0\n",
        "            elif ttc < 2.0:\n",
        "                reason = \"Close Following\"\n",
        "            else:\n",
        "                reason = \"Normal Deceleration\"\n",
        "\n",
        "        # Adjacent lane (cut-in)\n",
        "        elif location == 1:\n",
        "            if actions[1] == 1 or actions[2] == 1:\n",
        "                reason = \"Dangerous Cut-in\"\n",
        "                semantic_bonus = 10.0\n",
        "                omega = 1.3\n",
        "            else:\n",
        "                reason = \"Approaching\"\n",
        "                omega = 0.8\n",
        "\n",
        "        final_risk = min(base_score * omega + semantic_bonus, 100.0)\n",
        "\n",
        "        return {\n",
        "            \"score\": round(final_risk, 2),\n",
        "            \"ttc\": round(ttc, 2) if ttc != float('inf') else \"Safe\",\n",
        "            \"reason\": reason,\n",
        "            \"level\": self._get_risk_level(final_risk),\n",
        "        }\n",
        "\n",
        "    def _get_risk_level(self, score):\n",
        "        if score > 60: return \"DANGER\"\n",
        "        if score > 30: return \"CAUTION\"\n",
        "        return \"SAFE\"\n"
      ],
      "metadata": {
        "id": "Sz7pLSMXKDOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import imageio\n",
        "from tqdm import tqdm\n",
        "\n",
        "def export_intent_risk_video(folder_path, output_name=\"Final_2D_Trajectory_Risk.mp4\"):\n",
        "    tracker = Sort(max_age=5, min_hits=2, iou_threshold=0.3)\n",
        "    risk_mgr = IntentAwareRiskManager(window_size=5)\n",
        "\n",
        "    img_files = sorted(glob.glob(os.path.join(folder_path, \"img/*.png\")))\n",
        "    if not img_files:\n",
        "        print(\"‚ùå Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°ú Ïò§Î•ò\")\n",
        "        return\n",
        "\n",
        "    sample = cv2.imread(img_files[0])\n",
        "    img_h, img_w, _ = sample.shape\n",
        "\n",
        "    writer = imageio.get_writer(output_name, fps=1, codec=\"libx264\", quality=8)\n",
        "    print(\"üé¨ Risk video generating...\")\n",
        "\n",
        "    # Risk level ‚Üí bounding box color\n",
        "    RISK_COLOR = {\n",
        "        \"DANGER\":  (0, 0, 255),     # Red\n",
        "        \"WARNING\": (0, 165, 255),   # Orange\n",
        "        \"CAUTION\": (0, 255, 255),   # Yellow\n",
        "        \"SAFE\":    (255, 0, 0)      # Blue\n",
        "    }\n",
        "\n",
        "    # Location text\n",
        "    LOC_LABEL = {\n",
        "        0: \"Ego\",\n",
        "        1: \"Adjacent\",\n",
        "        2: \"Opposite\",\n",
        "        3: \"Intersection\",\n",
        "        4: \"Parking\"\n",
        "    }\n",
        "\n",
        "    # Action text color\n",
        "    ACTION_TEXT_COLOR = {\n",
        "        \"BRAKE\":     (0, 0, 255),\n",
        "        \"LEFT\":      (255, 255, 0),\n",
        "        \"RIGHT\":     (0, 255, 255),\n",
        "        \"EMERGENCY\": (255, 0, 255)\n",
        "    }\n",
        "\n",
        "    def actions_to_text(actions):\n",
        "        texts = []\n",
        "        if actions[0] == 1: texts.append(\"BRAKE\")\n",
        "        if actions[1] == 1: texts.append(\"LEFT\")\n",
        "        if actions[2] == 1: texts.append(\"RIGHT\")\n",
        "        if actions[3] == 1: texts.append(\"EMERGENCY\")\n",
        "        return texts\n",
        "\n",
        "    for img_p in tqdm(img_files):\n",
        "        frame = cv2.imread(img_p)\n",
        "        label_p = img_p.replace(\"img\", \"new_txt\").replace(\".png\", \".txt\")\n",
        "\n",
        "        dets, meta = [], []\n",
        "\n",
        "        if os.path.exists(label_p):\n",
        "            with open(label_p) as f:\n",
        "                for line in f:\n",
        "                    d = list(map(float, line.split()))\n",
        "                    dets.append(d[0:4])\n",
        "                    meta.append({\n",
        "                        \"location\": int(d[5]),\n",
        "                        \"actions\": d[6:10]\n",
        "                    })\n",
        "\n",
        "        if len(dets) > 0:\n",
        "            tracks = tracker.update(np.array(dets))\n",
        "\n",
        "            for x1, y1, x2, y2, tid in tracks:\n",
        "                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
        "                bbox = [x1, y1, x2, y2]\n",
        "\n",
        "                # detection ‚Üî track Îß§Ïπ≠ (nearest x)\n",
        "                i = np.argmin([abs(x1 - d[0]) for d in dets])\n",
        "                location = meta[i][\"location\"]\n",
        "                actions = meta[i][\"actions\"]\n",
        "\n",
        "                res = risk_mgr.calculate_risk(\n",
        "                    track_id=int(tid),\n",
        "                    bbox=bbox,\n",
        "                    location=location,\n",
        "                    actions=actions,\n",
        "                    fps=20,\n",
        "                    img_w=img_w,\n",
        "                    img_h=img_h\n",
        "                )\n",
        "\n",
        "                level = res[\"level\"]\n",
        "                color = RISK_COLOR[level]\n",
        "                loc_text = LOC_LABEL.get(location, \"Unknown\")\n",
        "                action_texts = actions_to_text(actions)\n",
        "\n",
        "                thickness = 3 if level == \"DANGER\" else \\\n",
        "                            3 if level in [\"WARNING\", \"CAUTION\"] else 2\n",
        "\n",
        "                # ===============================\n",
        "                # 1. Bounding Box\n",
        "                # ===============================\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)\n",
        "\n",
        "                # ===============================\n",
        "                # 2. Text Rendering\n",
        "                # ===============================\n",
        "                if level == \"SAFE\":\n",
        "                    cv2.putText(frame,\n",
        "                                loc_text,\n",
        "                                (x1, y1 - 20),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                                0.45,\n",
        "                                (200, 200, 200),\n",
        "                                1)\n",
        "\n",
        "                    y_action = y1 - 4\n",
        "                    for act in action_texts:\n",
        "                        cv2.putText(frame,\n",
        "                                    f\"{act}\",\n",
        "                                    (x1, y_action),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                                    0.45,\n",
        "                                    ACTION_TEXT_COLOR[act],\n",
        "                                    1)\n",
        "                        y_action += 14\n",
        "\n",
        "                else:\n",
        "                    cv2.putText(frame,\n",
        "                                f\"[{level}] {res['score']} TTC:{res['ttc']}s\",\n",
        "                                (x1, y1 - 68),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                                0.5,\n",
        "                                color,\n",
        "                                2)\n",
        "\n",
        "                    cv2.putText(frame,\n",
        "                                f\"Cause: {res['reason']}\",\n",
        "                                (x1, y1 - 52),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                                0.45,\n",
        "                                (255, 255, 255),\n",
        "                                1)\n",
        "\n",
        "                    cv2.putText(frame,\n",
        "                                loc_text,\n",
        "                                (x1, y1 - 36),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                                0.45,\n",
        "                                (200, 200, 200),\n",
        "                                1)\n",
        "\n",
        "                    y_action = y1 - 20\n",
        "                    for act in action_texts:\n",
        "                        cv2.putText(frame,\n",
        "                                    f\"{act}\",\n",
        "                                    (x1, y_action),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                                    0.45,\n",
        "                                    ACTION_TEXT_COLOR[act],\n",
        "                                    1)\n",
        "                        y_action += 14\n",
        "\n",
        "                    if \"duration\" in res:\n",
        "                        cv2.putText(frame,\n",
        "                                    f\"Duration: {res['duration']}s\",\n",
        "                                    (x1, y2 + 14),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                                    0.45,\n",
        "                                    color,\n",
        "                                    1)\n",
        "\n",
        "        writer.append_data(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    writer.close()\n",
        "    print(f\"‚úÖ Saved: {output_name}\")\n"
      ],
      "metadata": {
        "id": "n-zAi6TKKHr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "from pathlib import Path\n",
        "folder = Path(\"/content/split_raw_data/test/ETRINear_Fog\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "Huk1j0DThEmF",
        "outputId": "5ca74d85-fe7b-4691-f87a-65d850125b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'PosixPath' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2694661219.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/split_raw_data/test/ETRINear_Fog\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'PosixPath' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_FOLDER = \"/content/dataset/train/ETRINear_Fog\"\n",
        "export_intent_risk_video(TEST_FOLDER, \"ETRINear_Fog_result.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M480t_CxKLQD",
        "outputId": "22eafb9c-8541-44ab-998f-e2d017e3652e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé¨ Risk video generating...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [04:56<00:00,  4.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved: ETRINear_Fog_result.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "src = \"/content/2D_Trajectory_Risk_5.mp4\"\n",
        "dst_dir = \"/content/drive/MyDrive/risk_results\"\n",
        "os.makedirs(dst_dir, exist_ok=True)\n",
        "\n",
        "dst = os.path.join(dst_dir, os.path.basename(src))\n",
        "shutil.copy2(src, dst)\n",
        "\n",
        "print(f\"‚úÖ Moved to {dst}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoEcG5AiM-WD",
        "outputId": "09df00d7-cb00-41a0-d248-a63929cf090b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Moved to /content/drive/MyDrive/risk_results/2D_Trajectory_Risk_5.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "def reorganize_dataset_to_folders(base_path):\n",
        "    \"\"\"\n",
        "    /content/split_raw_data/test Í≤ΩÎ°úÎ•º ÏûÖÎ†•Î∞õÏïÑ\n",
        "    ÎÇ¥Î∂ÄÏùò img, new_txt ÌååÏùºÎì§ÏùÑ Í∞ÅÍ∞ÅÏùò ÏãúÎÇòÎ¶¨Ïò§ Ìè¥ÎçîÎ°ú Îã§Ïãú Î¨∂Ïñ¥Ï§çÎãàÎã§.\n",
        "    \"\"\"\n",
        "    img_source_dir = os.path.join(base_path, 'img')\n",
        "    txt_source_dir = os.path.join(base_path, 'new_txt')\n",
        "\n",
        "    # 1. Î™®Îì† Ïù¥ÎØ∏ÏßÄ ÌååÏùº Î™©Î°ù Í∞ÄÏ†∏Ïò§Í∏∞\n",
        "    img_files = glob.glob(os.path.join(img_source_dir, \"*.png\"))\n",
        "\n",
        "    print(f\"üì¶ Ï¥ù {len(img_files)}Í∞úÏùò ÌååÏùºÏùÑ Ïû¨Ï†ïÎ†¨Ìï©ÎãàÎã§...\")\n",
        "\n",
        "    for img_path in tqdm(img_files):\n",
        "        # ÌååÏùºÎ™ÖÎßå Ï∂îÏ∂ú (Ïòà: ETRINear_Fog_00003427.png)\n",
        "        full_file_name = os.path.basename(img_path)\n",
        "\n",
        "        # ÌååÏùºÎ™ÖÏóêÏÑú Ìè¥ÎçîÎ™ÖÍ≥º Ïã§Ï†ú ÌååÏùºÎ™Ö Î∂ÑÎ¶¨\n",
        "        # (ÎßàÏßÄÎßâ '_'Î•º Í∏∞Ï§ÄÏúºÎ°ú ÎÇòÎàî - ÏõêÎ≥∏ ÌååÏùºÎ™ÖÏù¥ 000000.png ÌòïÌÉúÏù¥ÎØÄÎ°ú)\n",
        "        last_underscore_idx = full_file_name.rfind('_')\n",
        "        if last_underscore_idx == -1:\n",
        "            continue\n",
        "\n",
        "        folder_name = full_file_name[:last_underscore_idx]\n",
        "        actual_file_name = full_file_name[last_underscore_idx + 1:]\n",
        "\n",
        "        # 2. ÏÉàÎ°úÏö¥ Ìè¥Îçî Íµ¨Ï°∞ ÏÉùÏÑ± (Ïòà: test/ETRINear_Fog/img)\n",
        "        new_img_dir = os.path.join(base_path, folder_name, 'img')\n",
        "        new_txt_dir = os.path.join(base_path, folder_name, 'new_txt')\n",
        "\n",
        "        os.makedirs(new_img_dir, exist_ok=True)\n",
        "        os.makedirs(new_txt_dir, exist_ok=True)\n",
        "\n",
        "        # 3. Ïù¥ÎØ∏ÏßÄ ÌååÏùº Ïù¥Îèô\n",
        "        target_img_path = os.path.join(new_img_dir, actual_file_name)\n",
        "        shutil.move(img_path, target_img_path)\n",
        "\n",
        "        # 4. ÎåÄÏùëÌïòÎäî ÌÖçÏä§Ìä∏ ÌååÏùº Ïù¥Îèô\n",
        "        # Ïù¥ÎØ∏ÏßÄ ÌååÏùºÎ™ÖÍ≥º ÎèôÏùºÌïú Ïù¥Î¶ÑÏùò .txt ÌååÏùºÏùÑ Ï∞æÏùå\n",
        "        txt_file_name = full_file_name.replace('.png', '.txt')\n",
        "        old_txt_path = os.path.join(txt_source_dir, txt_file_name)\n",
        "\n",
        "        if os.path.exists(old_txt_path):\n",
        "            actual_txt_name = actual_file_name.replace('.png', '.txt')\n",
        "            target_txt_path = os.path.join(new_txt_dir, actual_txt_name)\n",
        "            shutil.move(old_txt_path, target_txt_path)\n",
        "\n",
        "    # 5. ÎπÑÏñ¥ÏûàÎäî ÏõêÎûòÏùò img, new_txt Ìè¥Îçî ÏÇ≠Ï†ú (ÏÑ†ÌÉù ÏÇ¨Ìï≠)\n",
        "    if not os.listdir(img_source_dir):\n",
        "        os.rmdir(img_source_dir)\n",
        "    if not os.listdir(txt_source_dir):\n",
        "        os.rmdir(txt_source_dir)\n",
        "\n",
        "    print(f\"‚ú® Ïû¨Ï†ïÎ†¨ ÏôÑÎ£å! {base_path} ÎÇ¥Î∂ÄÎ•º ÌôïÏù∏ÌïòÏÑ∏Ïöî.\")"
      ],
      "metadata": {
        "id": "2ak__ZjfkTY6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_BASE_PATH = '/content/split_raw_data/test'\n",
        "reorganize_dataset_to_folders(TEST_BASE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA361Abzgt4m",
        "outputId": "d82e7049-81b9-4ae4-ba5f-082262e68fed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Ï¥ù 3740Í∞úÏùò ÌååÏùºÏùÑ Ïû¨Ï†ïÎ†¨Ìï©ÎãàÎã§...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3740/3740 [00:00<00:00, 13525.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ú® Ïû¨Ï†ïÎ†¨ ÏôÑÎ£å! /content/split_raw_data/test ÎÇ¥Î∂ÄÎ•º ÌôïÏù∏ÌïòÏÑ∏Ïöî.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zjDMt1oWg59o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}