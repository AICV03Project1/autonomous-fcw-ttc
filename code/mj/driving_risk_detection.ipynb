{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸"],"metadata":{"id":"sN09ANxPCWt0"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"azK4f36gIXoO","outputId":"2f3473db-1d74-4d65-a4b1-94e72231395b","executionInfo":{"status":"ok","timestamp":1768451824707,"user_tz":-540,"elapsed":13982,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n"]},{"cell_type":"markdown","source":["ë°ì´í„°ì…‹ ë³µì‚¬"],"metadata":{"id":"fX1Y7iE1CZI-"}},{"cell_type":"code","source":["!cp \"/content/drive/MyDrive/OD_project/raw/ì°¨ëŸ‰ìƒíƒœì¸ì‹ (1).zip\" /content"],"metadata":{"id":"vhE6zOxsIZCD","executionInfo":{"status":"ok","timestamp":1768452480291,"user_tz":-540,"elapsed":643377,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!cp -r \"/content/drive/MyDrive/OD_project/Capture\" /content"],"metadata":{"id":"iuZJkEALe8YF","executionInfo":{"status":"ok","timestamp":1768461033850,"user_tz":-540,"elapsed":9860,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":["!cp -r \"/content/drive/MyDrive/OD_project/á„‰á…¡á„€á…©á„‹á…§á†¼á„‰á…¡á†¼_new.zip\" /content"],"metadata":{"id":"MAQDrT6vriFw","executionInfo":{"status":"ok","timestamp":1768464241683,"user_tz":-540,"elapsed":19640,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}}},"execution_count":97,"outputs":[]},{"cell_type":"markdown","source":["ë°ì´í„°ì…‹ ì••ì¶• í•´ì œ"],"metadata":{"id":"pUE26fyiCabx"}},{"cell_type":"code","source":["!unzip -q \"/content/ì°¨ëŸ‰ìƒíƒœì¸ì‹ (1).zip\" -d /content/my_dataset"],"metadata":{"id":"gm9Rxw2ZIZGa","executionInfo":{"status":"ok","timestamp":1768452935872,"user_tz":-540,"elapsed":439149,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!unzip -q \"/content/á„‰á…¡á„€á…©á„‹á…§á†¼á„‰á…¡á†¼_new.zip\" -d /content/sago"],"metadata":{"id":"DmE6tMDNrw_y","executionInfo":{"status":"ok","timestamp":1768464343394,"user_tz":-540,"elapsed":11065,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}}},"execution_count":99,"outputs":[]},{"cell_type":"markdown","source":["csv ë‚´ìš©ì— ë§ê²Œ íŒŒì¼ ë‚˜ëˆ„ê¸°"],"metadata":{"id":"SJVz8xMuCcdn"}},{"cell_type":"code","source":["import os\n","import glob\n","import cv2\n","import shutil\n","import pandas as pd\n","\n","\n","def prepare_yolo_dataset_by_csv(root_path, csv_path, output_path):\n","    df = pd.read_csv(csv_path, encoding='utf-8-sig')\n","    df = df[['env', 'split']].dropna()\n","    df = df[df['split'].isin(['train', 'val', 'test'])]\n","\n","    split_map = dict(zip(df['env'], df['split']))\n","    print(f\"âœ… CSV ë¡œë“œ ì™„ë£Œ: {len(split_map)}ê°œì˜ í™˜ê²½(env) ì„¤ì • ì½ìŒ.\")\n","\n","    image_paths = glob.glob(os.path.join(root_path, \"**/img/*.png\"), recursive=True)\n","    print(f\"ì´ {len(image_paths)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n","\n","    if len(image_paths) == 0:\n","        print(\"âŒ ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. root_path í™•ì¸ í•„ìš”\")\n","        return\n","\n","    for split in ['train', 'val', 'test']:\n","        os.makedirs(os.path.join(output_path, split, 'images'), exist_ok=True)\n","        os.makedirs(os.path.join(output_path, split, 'labels'), exist_ok=True)\n","\n","    processed_count = 0\n","    missing_env_count = 0\n","\n","    for img_path in image_paths:\n","        folder_name = img_path.split(os.sep)[-3]\n","        file_name = os.path.basename(img_path)\n","\n","        target_split = split_map.get(folder_name)\n","        if not target_split:\n","            missing_env_count += 1\n","            continue\n","\n","        new_base = f\"{folder_name}_{file_name}\"\n","        new_label = new_base.replace(\".png\", \".txt\")\n","\n","        org_label_path = img_path.replace(\"img\", \"new_txt\").replace(\".png\", \".txt\")\n","        if not os.path.exists(org_label_path):\n","            continue\n","\n","        img = cv2.imread(img_path)\n","        if img is None:\n","            continue\n","        h, w, _ = img.shape\n","\n","        yolo_labels = []\n","        with open(org_label_path) as f:\n","            for line in f:\n","                data = list(map(float, line.split()))\n","                if len(data) < 5:\n","                    continue\n","\n","                x1, y1, x2, y2 = data[:4]\n","                class_id = int(data[4])\n","\n","                xc = ((x1 + x2) / 2) / w\n","                yc = ((y1 + y2) / 2) / h\n","                nw = (x2 - x1) / w\n","                nh = (y2 - y1) / h\n","\n","                yolo_labels.append(\n","                    f\"{class_id} {xc:.6f} {yc:.6f} {nw:.6f} {nh:.6f}\"\n","                )\n","\n","        if yolo_labels:\n","            shutil.copy(\n","                img_path,\n","                os.path.join(output_path, target_split, \"images\", new_base)\n","            )\n","            with open(\n","                os.path.join(output_path, target_split, \"labels\", new_label), \"w\"\n","            ) as f:\n","                f.write(\"\\n\".join(yolo_labels))\n","\n","            processed_count += 1\n","\n","    print(\"-\" * 30)\n","    print(\"âœ¨ ì²˜ë¦¬ ì™„ë£Œ!\")\n","    print(f\"- ì„±ê³µì ìœ¼ë¡œ ë³€í™˜ëœ ì´ë¯¸ì§€: {processed_count}ì¥\")\n","    print(f\"- CSVì— ì •ì˜ë˜ì§€ ì•Šì•„ ì œì™¸ëœ í´ë”: {missing_env_count}ê°œ\")\n","    print(f\"- ê²°ê³¼ ì €ì¥ì†Œ: {os.path.abspath(output_path)}\")\n"],"metadata":{"id":"kSGA1eJNIZJU","executionInfo":{"status":"ok","timestamp":1768453022450,"user_tz":-540,"elapsed":1448,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["prepare_yolo_dataset_by_csv(\n","    root_path=\"/content/my_dataset\",\n","    csv_path=\"/content/drive/MyDrive/OD_project/split_assignment.csv\",\n","    output_path=\"/content/my_car_dataset\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V0iwQzoaIZLn","outputId":"52d4948c-ed9f-499e-c2b3-6f2171a49034","executionInfo":{"status":"ok","timestamp":1768453689249,"user_tz":-540,"elapsed":664557,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… CSV ë¡œë“œ ì™„ë£Œ: 165ê°œì˜ í™˜ê²½(env) ì„¤ì • ì½ìŒ.\n","ì´ 42096ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n","------------------------------\n","âœ¨ ì²˜ë¦¬ ì™„ë£Œ!\n","- ì„±ê³µì ìœ¼ë¡œ ë³€í™˜ëœ ì´ë¯¸ì§€: 33187ì¥\n","- CSVì— ì •ì˜ë˜ì§€ ì•Šì•„ ì œì™¸ëœ í´ë”: 8909ê°œ\n","- ê²°ê³¼ ì €ì¥ì†Œ: /content/my_car_dataset\n"]}]},{"cell_type":"markdown","source":["ultralytics ë‹¤ìš´ë¡œë“œ"],"metadata":{"id":"C7JsYlI9CovY"}},{"cell_type":"code","source":["!pip install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UYIuLg9-I1ua","outputId":"8b42d43a-56b2-429c-89b1-cf8be1aad094","executionInfo":{"status":"ok","timestamp":1768453712453,"user_tz":-540,"elapsed":11880,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.4.2-py3-none-any.whl.metadata (36 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n","Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.3.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.2)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n","Downloading ultralytics-8.4.2-py3-none-any.whl (1.2 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n","Installing collected packages: ultralytics-thop, ultralytics\n","Successfully installed ultralytics-8.4.2 ultralytics-thop-2.0.18\n"]}]},{"cell_type":"markdown","source":["ResNet + FPN ëª¨ë¸ ì •ì˜"],"metadata":{"id":"40s8Ikx8Crb6"}},{"cell_type":"code","source":["#2-2) ëª¨ë¸ ì •ì˜ (ResNet50-FPN + ROIAlign + shared head + 2 heads)\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n","from torchvision.ops import MultiScaleRoIAlign\n","from torchvision.models.detection.faster_rcnn import TwoMLPHead\n","from torchvision.models.detection.transform import GeneralizedRCNNTransform\n","\n","def build_backbone_resnet50_fpn():\n","    # torchvision ë²„ì „ í˜¸í™˜ ì²˜ë¦¬\n","    try:\n","        from torchvision.models import ResNet50_Weights\n","        return resnet_fpn_backbone(\"resnet50\", weights=ResNet50_Weights.DEFAULT)\n","    except Exception:\n","        # êµ¬ë²„ì „ì—ì„œëŠ” pretrained ì¸ìë¥¼ ë°›ì„ ìˆ˜ ìˆìŒ\n","        return resnet_fpn_backbone(\"resnet50\", pretrained=True)\n","\n","class ROIClassifier(nn.Module):\n","    def __init__(\n","        self,\n","        num_location=5,\n","        num_action=4,\n","        pos_weight=None,                 # torch.Tensor[4]\n","        min_size=640, max_size=1024,      # transform resize\n","        roi_output_size=7,\n","        roi_sampling_ratio=2,\n","        representation_size=1024,\n","        image_mean=(0.485,0.456,0.406),\n","        image_std=(0.229,0.224,0.225),\n","    ):\n","        super().__init__()\n","\n","        self.transform = GeneralizedRCNNTransform(\n","            min_size=min_size,\n","            max_size=max_size,\n","            image_mean=list(image_mean),\n","            image_std=list(image_std),\n","        )\n","\n","        self.backbone = build_backbone_resnet50_fpn()\n","        out_channels = self.backbone.out_channels  # usually 256\n","\n","        self.roi_pooler = MultiScaleRoIAlign(\n","            featmap_names=[\"0\",\"1\",\"2\",\"3\"],\n","            output_size=roi_output_size,\n","            sampling_ratio=roi_sampling_ratio,\n","        )\n","\n","        self.box_head = TwoMLPHead(\n","            in_channels=out_channels * roi_output_size * roi_output_size,\n","            representation_size=representation_size,\n","        )\n","\n","        self.location_head = nn.Linear(representation_size, num_location)\n","        self.action_head   = nn.Linear(representation_size, num_action)\n","\n","        # action lossìš© pos_weight ì €ì¥\n","        if pos_weight is not None:\n","            self.register_buffer(\"pos_weight\", pos_weight.clone().detach())\n","        else:\n","            self.pos_weight = None\n","\n","    def forward(self, images, targets=None):\n","        \"\"\"\n","        images: list[Tensor(3,H,W)]\n","        targets: list[dict] with keys:\n","          boxes: FloatTensor[N,4] xyxy (ì›ë³¸ í”½ì…€ ì¢Œí‘œê³„)\n","          location: LongTensor[N]\n","          action: FloatTensor[N,4] (0/1)\n","        \"\"\"\n","        if self.training and targets is None:\n","            raise ValueError(\"Training requires targets\")\n","\n","        image_list, targets = self.transform(images, targets)\n","        features = self.backbone(image_list.tensors)  # dict[str,Tensor]\n","\n","        boxes = [t[\"boxes\"] for t in targets]\n","        pooled = self.roi_pooler(features, boxes, image_list.image_sizes)  # [sumN, C, S, S]\n","        pooled = pooled.flatten(start_dim=1)                               # [sumN, C*S*S]\n","        rep = self.box_head(pooled)                                        # [sumN, repr]\n","\n","        loc_logits = self.location_head(rep)  # [sumN, 5]\n","        act_logits = self.action_head(rep)    # [sumN, 4]\n","\n","        if self.training:\n","            loc_t = torch.cat([t[\"location\"] for t in targets], dim=0)  # [sumN]\n","            act_t = torch.cat([t[\"action\"] for t in targets], dim=0)    # [sumN,4]\n","\n","            loss_loc = F.cross_entropy(loc_logits, loc_t)\n","\n","            if self.pos_weight is None:\n","                loss_act = F.binary_cross_entropy_with_logits(act_logits, act_t)\n","            else:\n","                loss_act = F.binary_cross_entropy_with_logits(\n","                    act_logits, act_t, pos_weight=self.pos_weight\n","                )\n","\n","            return {\"loss_location\": loss_loc, \"loss_action\": loss_act}\n","\n","        # inference\n","        return F.softmax(loc_logits, dim=1), torch.sigmoid(act_logits)\n"],"metadata":{"id":"v7C9Ba6LIZOO","executionInfo":{"status":"ok","timestamp":1768453730348,"user_tz":-540,"elapsed":12895,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["YOLO, ResNet pt ì ìš©"],"metadata":{"id":"ki4EUtlhCwY6"}},{"cell_type":"code","source":["import glob\n","import os\n","import cv2\n","import torch\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","from PIL import Image as PILImage\n","import torchvision.transforms.functional as TF\n","\n","# --- 1. ì„¤ì • ---\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","#dataset_root = '/content/my_car_dataset'\n","dataset_root = '/content/sago'\n","output_root = '/content/sago_SafeDrive_T4_HighPerf/test_sequences_combined'\n","os.makedirs(output_root, exist_ok=True)\n","\n","# ì„±ë¯¼ë‹˜ ëª¨ë¸ ê°€ì¤‘ì¹˜ ê²½ë¡œ â˜…\n","TEAMMATE_WEIGHTS_PATH = \"/content/drive/MyDrive/OD_project/best_by_microf1_bestth2.pt\"\n","\n","# --- 2. ëª¨ë¸ ë¡œë“œ ---\n","# (1) YOLO ëª¨ë¸ ë¡œë“œ\n","if 'model' in globals():\n","    yolo_model = model\n","    print(\"âœ… YOLO ëª¨ë¸(ë©”ëª¨ë¦¬) ì‚¬ìš©\")\n","else:\n","    from ultralytics import YOLO\n","    yolo_path = '/content/drive/MyDrive/OD_project/yolo11n_param_best.pt'\n","    if os.path.exists(yolo_path):\n","        yolo_model = YOLO(yolo_path)\n","        print(\"âœ… YOLO ëª¨ë¸ ìƒˆë¡œ ë¡œë“œ ì™„ë£Œ\")\n","    else:\n","        raise FileNotFoundError(\"âŒ YOLO ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n","\n","# (2) ROI ëª¨ë¸(íŒ€ì› ëª¨ë¸) ë¡œë“œ\n","print(f\"ğŸ“‚ íŒ€ì› ëª¨ë¸ ë¡œë“œ ì‹œë„: {TEAMMATE_WEIGHTS_PATH}\")\n","if not os.path.exists(TEAMMATE_WEIGHTS_PATH):\n","    raise FileNotFoundError(\"âŒ íŒ€ì› ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n","\n","try:\n","    # ëª¨ë¸ êµ¬ì¡° ìƒì„± (ROIClassifier í´ë˜ìŠ¤ê°€ ë©”ëª¨ë¦¬ì— ìˆì–´ì•¼ í•¨)\n","    roi_model = ROIClassifier(num_location=5, num_action=4).to(device)\n","\n","    # ê°€ì¤‘ì¹˜ íŒŒì¼ ë¡œë“œ\n","    ckpt = torch.load(TEAMMATE_WEIGHTS_PATH, map_location=device, weights_only=False)\n","\n","    # state_dict í‚¤ ì²˜ë¦¬\n","    if isinstance(ckpt, dict) and \"model_state\" in ckpt:\n","        state_dict = ckpt[\"model_state\"]\n","    else:\n","        state_dict = ckpt\n","\n","    # ë¡œë“œ (strict=Falseë¡œ ì„¤ì •í•˜ì—¬ pos_weight ë“± ë¶ˆì¼ì¹˜ ë¬´ì‹œ)\n","    roi_model.load_state_dict(state_dict, strict=False)\n","    roi_model.eval()\n","    print(\"âœ… íŒ€ì› ëª¨ë¸(ROI) ë¡œë“œ ì„±ê³µ!\")\n","except Exception as e:\n","    print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n","    raise e\n","\n","\"\"\"\n","# --- 3. ì‹œí€€ìŠ¤ ê·¸ë£¹í™” ---\n","all_test_images = glob.glob(os.path.join(dataset_root, 'test', 'images', '*.png'))\n","sequences = {}\n","\n","for img_path in all_test_images:\n","    filename = os.path.basename(img_path)\n","    try:\n","        # íŒŒì¼ëª…ì—ì„œ ì‹œí€€ìŠ¤ ì´ë¦„ ì¶”ì¶œ\n","        seq_name = filename.rsplit('_', 1)[0]\n","        if seq_name not in sequences:\n","            sequences[seq_name] = []\n","        sequences[seq_name].append(img_path)\n","    except IndexError:\n","        pass\n","\n","print(f\"ğŸ“‚ ì´ {len(sequences)}ê°œì˜ ì‹œí€€ìŠ¤ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. í†µí•© ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n","\"\"\"\n","# --- 3. ì‹œí€€ìŠ¤ ê·¸ë£¹í™” (ìˆ˜ì • ë²„ì „) ---\n","\n","# íŒ¨í„´ 1: ì‚¬ìš©ìê°€ ì§€ì •í•œ í´ë” ë°”ë¡œ ì•„ë˜ ëª¨ë“  png ì°¾ê¸°\n","# íŒ¨í„´ 2: í•˜ìœ„ í´ë” ì–´ë””ë“  ìˆëŠ” ëª¨ë“  png ì°¾ê¸° (recursive=True)\n","search_pattern = os.path.join(dataset_root, '**', '*.png')\n","all_test_images = glob.glob(search_pattern, recursive=True)\n","\n","sequences = {}\n","\n","if not all_test_images:\n","    print(f\"âŒ ì´ë¯¸ì§€ë¥¼ í•˜ë‚˜ë„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í˜„ì¬ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {dataset_root}\")\n","else:\n","    for img_path in all_test_images:\n","        filename = os.path.basename(img_path)\n","\n","        # íŒŒì¼ëª…ì— '_'ê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì•ˆì „í•œ ë¶„ë¦¬\n","        if '_' in filename:\n","            seq_name = filename.rsplit('_', 1)[0]\n","        else:\n","            # ì–¸ë”ë°”ê°€ ì—†ìœ¼ë©´ í´ë” ì´ë¦„ì„ ì‹œí€€ìŠ¤ ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©\n","            seq_name = os.path.basename(os.path.dirname(img_path))\n","\n","        if seq_name not in sequences:\n","            sequences[seq_name] = []\n","        sequences[seq_name].append(img_path)\n","\n","    print(f\"ğŸ“‚ ì´ {len(sequences)}ê°œì˜ ì‹œí€€ìŠ¤ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤: {list(sequences.keys())}\")\n","\n","# --- 4. ë‚´ë¶€ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ ---\n","@torch.no_grad()\n","def process_single_frame(image_path, yolo_model, roi_model, device):\n","    img_cv = cv2.imread(image_path)\n","    if img_cv is None: return None, []\n","\n","    filename = os.path.basename(image_path)\n","\n","    # YOLO Input\n","    img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)\n","    img_pil = PILImage.fromarray(img_rgb)\n","\n","    # YOLO Inference\n","    yolo_results = yolo_model(img_rgb, verbose=False)\n","    boxes = yolo_results[0].boxes.xyxy.cpu()\n","    clss = yolo_results[0].boxes.cls.cpu().int()\n","    names = yolo_model.names\n","\n","    if len(boxes) == 0: return img_cv, []\n","\n","    # ROI Input\n","    img_tensor = TF.to_tensor(img_pil).to(device)\n","    target_dict = [{\"boxes\": boxes.to(device)}]\n","\n","    # ROI Inference\n","    loc_probs, act_probs = roi_model([img_tensor], target_dict)\n","    loc_preds = loc_probs.argmax(dim=1).cpu().numpy()\n","    act_probs = act_probs.cpu().numpy()\n","\n","    # Config\n","    LOC_NAMES = [\"My\", \"Next\", \"Opposite\", \"RoadSide\", \"None\"]\n","    ACT_NAMES = [\"Brake\", \"Left\", \"Right\", \"Hazard\"]\n","\n","    frame_detections = []\n","    output_img = img_cv.copy()\n","\n","    for i, box in enumerate(boxes.numpy()):\n","        x1, y1, x2, y2 = map(int, box)\n","        cls_id = int(clss[i])\n","        class_name = names[cls_id] if names and cls_id in names else str(cls_id)\n","\n","        loc_idx = int(loc_preds[i])\n","        loc_text = LOC_NAMES[loc_idx] if loc_idx < len(LOC_NAMES) else str(loc_idx)\n","\n","        # Actions\n","        act_vals = act_probs[i]\n","        is_active = (act_vals > 0.5).astype(int)\n","        actions_str = [ACT_NAMES[j] for j, active in enumerate(is_active) if active]\n","        act_text = \",\".join(actions_str) if actions_str else \"Normal\"\n","\n","        # Append Data\n","        frame_detections.append({\n","            \"Filename\": filename,\n","            \"Class_Name\": class_name,\n","            \"Location_Name\": loc_text,\n","            \"Action_String\": act_text,\n","            \"x1\": x1, \"y1\": y1, \"x2\": x2, \"y2\": y2,\n","            \"Class_ID\": cls_id,\n","            \"Location_ID\": loc_idx,\n","            \"Brake\": is_active[0], \"Left\": is_active[1], \"Right\": is_active[2], \"Hazard\": is_active[3]\n","        })\n","\n","        # Draw\n","        label = f\"[{class_name}] {loc_text}|{act_text}\"\n","        cv2.rectangle(output_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n","        (w_t, h_t), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n","        cv2.rectangle(output_img, (x1, y1 - 20), (x1 + w_t, y1), (0, 255, 0), -1)\n","        cv2.putText(output_img, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n","\n","    return output_img, frame_detections\n","\n","\"\"\"\n","# --- 5. ì „ì²´ ì‹œí€€ìŠ¤ ì‹¤í–‰ ---\n","for seq_name, img_list in tqdm(sequences.items(), desc=\"Total Progress\"):\n","    sorted_images = sorted(img_list)\n","    if not sorted_images: continue\n","\n","\"\"\"\n","\"\"\"\n","    # ì €ì¥ ê²½ë¡œ\n","    seq_save_dir = os.path.join(output_root, seq_name)\n","    os.makedirs(seq_save_dir, exist_ok=True)\n","\n","    video_path = os.path.join(seq_save_dir, f\"{seq_name}_combined.mp4\")\n","    csv_path = os.path.join(seq_save_dir, f\"{seq_name}_combined.csv\")\n","\n","    # Video Init\n","    sample = cv2.imread(sorted_images[0])\n","    h, w = sample.shape[:2]\n","    out = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'mp4v'), 20.0, (w, h))\n","\"\"\"\n","\"\"\"\n","    # ì €ì¥ ê²½ë¡œ\n","    seq_save_dir = os.path.join(output_root, seq_name)\n","    os.makedirs(seq_save_dir, exist_ok=True)\n","\n","    # ==========================================================\n","    # âœ… [ìˆ˜ì • í¬ì¸íŠ¸] íŒŒì¼ ì œëª© ì§€ì •í•˜ê¸°\n","    # ì›í•˜ëŠ” ì´ë¦„ì„ ë¬¸ìì—´ë¡œ ë„£ìœ¼ì„¸ìš”. (ì˜ˆ: \"Final_Result\")\n","    my_custom_name = \"Capture_result\"\n","\n","    # ë§Œì•½ ì‹œí€€ìŠ¤ ì´ë¦„ì„ ìœ ì§€í•˜ë©´ì„œ ë’¤ì— ê¸€ìë§Œ ë¶™ì´ê³  ì‹¶ë‹¤ë©´:\n","    # video_path = os.path.join(seq_save_dir, f\"{seq_name}_{my_custom_name}.mp4\")\n","\n","    video_path = os.path.join(seq_save_dir, f\"{my_custom_name}.mp4\")\n","    csv_path = os.path.join(seq_save_dir, f\"{my_custom_name}.csv\")\n","    # ==========================================================\n","\n","    # Video Init\n","    sample = cv2.imread(sorted_images[0])\n","    h, w = sample.shape[:2]\n","    out = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'mp4v'), 20.0, (w, h))\n","\n","    # ... ì´í•˜ ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼ ...\n","\n","    seq_detections = []\n","\n","    for img_path in sorted_images:\n","        res_img, dets = process_single_frame(img_path, yolo_model, roi_model, device)\n","        if res_img is not None:\n","            out.write(res_img)\n","            seq_detections.extend(dets)\n","\n","    out.release()\n","\n","    if seq_detections:\n","        df = pd.DataFrame(seq_detections)\n","        cols = [\"Filename\", \"x1\", \"y1\", \"x2\", \"y2\", \"Class_ID\", \"Location_ID\", \"Brake\", \"Left\", \"Right\", \"Hazard\", \"Class_Name\", \"Location_Name\", \"Action_String\"]\n","        exist_cols = [c for c in cols if c in df.columns]\n","        df[exist_cols].to_csv(csv_path, index=False, encoding='utf-8-sig')\n","\n","print(f\"\\nâœ¨ ëª¨ë“  í†µí•© ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ê²½ë¡œ: {output_root}\")\n","\"\"\"\n","\n","# --- 5. ì „ì²´ ì‹œí€€ìŠ¤ ì‹¤í–‰ ---\n","for seq_name, img_list in tqdm(sequences.items(), desc=\"Total Progress\"):\n","    sorted_images = sorted(img_list)\n","    if not sorted_images:\n","        continue\n","\n","    # ==========================================================\n","    # âœ… [íŒŒì¼ëª… ì •ì œ] seq_nameì— .mp4 ë“±ì´ í¬í•¨ëœ ê²½ìš° ì œê±°\n","    # ì˜ˆ: \"video.mp4\" -> \"video_mp4\" ë˜ëŠ” \"video\"ë¡œ ë³€ê²½\n","    clean_seq_name = seq_name.replace('.', '_')\n","\n","    # ì €ì¥ ê²½ë¡œ ì„¤ì • (í´ë”ëª…ë„ ê¹¨ë—í•˜ê²Œ ìœ ì§€)\n","    seq_save_dir = os.path.join(output_root, clean_seq_name)\n","    os.makedirs(seq_save_dir, exist_ok=True)\n","\n","    # âœ… [íŒŒì¼ëª… ì§€ì •]\n","    file_title = f\"{clean_seq_name}_analysis\"\n","\n","    video_path = os.path.join(seq_save_dir, f\"{file_title}.mp4\")\n","    csv_path = os.path.join(seq_save_dir, f\"{file_title}.csv\")\n","    # ==========================================================\n","\n","    # Video Init\n","    sample = cv2.imread(sorted_images[0])\n","    if sample is None:\n","        continue\n","\n","    h, w = sample.shape[:2]\n","    out = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'mp4v'), 20.0, (w, h))\n","\n","    seq_detections = []\n","\n","    for img_path in sorted_images:\n","        res_img, dets = process_single_frame(img_path, yolo_model, roi_model, device)\n","        if res_img is not None:\n","            out.write(res_img)\n","            seq_detections.extend(dets)\n","\n","    out.release()\n","\n","    if seq_detections:\n","        df = pd.DataFrame(seq_detections)\n","        cols = [\"Filename\", \"x1\", \"y1\", \"x2\", \"y2\", \"Class_ID\", \"Location_ID\",\n","                \"Brake\", \"Left\", \"Right\", \"Hazard\", \"Class_Name\",\n","                \"Location_Name\", \"Action_String\"]\n","        exist_cols = [c for c in cols if c in df.columns]\n","        df[exist_cols].to_csv(csv_path, index=False, encoding='utf-8-sig')\n","\n","print(f\"\\nâœ¨ ëª¨ë“  í†µí•© ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ê²½ë¡œ: {output_root}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YFE_ZudOIZQ0","outputId":"ae28ee63-9247-4804-8fa8-3dcc94464556","executionInfo":{"status":"ok","timestamp":1768464827933,"user_tz":-540,"elapsed":47830,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}}},"execution_count":100,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… YOLO ëª¨ë¸ ìƒˆë¡œ ë¡œë“œ ì™„ë£Œ\n","ğŸ“‚ íŒ€ì› ëª¨ë¸ ë¡œë“œ ì‹œë„: /content/drive/MyDrive/OD_project/best_by_microf1_bestth2.pt\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'backbone_name' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["âœ… íŒ€ì› ëª¨ë¸(ROI) ë¡œë“œ ì„±ê³µ!\n","ğŸ“‚ ì´ 11ê°œì˜ ì‹œí€€ìŠ¤ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤: ['bb_1_210701_vehicle_217_21650.mp4', 'bb_1_160612_vehicle_212_53256.mp4', 'bb_1_141024_vehicle_46_180.mp4', 'bb_1_211026_vehicle_144_301.mp4', 'bb_1_170304_vehicle_114_075.mp4', 'bb_1_150402_vehicle_142_073.mp4', 'bb_1_181121_vehicle_117_045.mp4', 'bb_1_200714_vehicle_200_28840.mp4', 'bb_1_210414_vehicle_244_50609.mp4', 'bb_1_210114_vehicle_253_50073.mp4', 'bb_1_210522_vehicle_315_061.mp4']\n"]},{"output_type":"stream","name":"stderr","text":["Total Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:46<00:00,  4.20s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","âœ¨ ëª¨ë“  í†µí•© ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ê²½ë¡œ: /content/sago_SafeDrive_T4_HighPerf/test_sequences_combined\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["ì´í›„ ë‹¨ê³„ë¥¼ ìœ„í•œ ë¦¬ì†ŒìŠ¤ ë‹¤ìš´ë¡œë“œ"],"metadata":{"id":"bvilGtEPC4K6"}},{"cell_type":"code","source":["# --- Install ---\n","!pip install numpy filterpy scipy imageio tqdm\n","!git clone https://github.com/abewley/sort.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h9AycpaEIZTb","outputId":"c9328f08-b98f-454e-cf16-a00b7521a651","executionInfo":{"status":"ok","timestamp":1768454496445,"user_tz":-540,"elapsed":8963,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Collecting filterpy\n","  Downloading filterpy-1.4.5.zip (177 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (2.37.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from filterpy) (3.10.0)\n","Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio) (11.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (4.61.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (25.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (3.3.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->filterpy) (1.17.0)\n","Building wheels for collected packages: filterpy\n","  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110460 sha256=1a9c590822c73eb60deea935f1be4c71b6b64f43a99200cb53f5c13506053aae\n","  Stored in directory: /root/.cache/pip/wheels/77/bf/4c/b0c3f4798a0166668752312a67118b27a3cd341e13ac0ae6ee\n","Successfully built filterpy\n","Installing collected packages: filterpy\n","Successfully installed filterpy-1.4.5\n","Cloning into 'sort'...\n","remote: Enumerating objects: 208, done.\u001b[K\n","remote: Counting objects: 100% (49/49), done.\u001b[K\n","remote: Compressing objects: 100% (9/9), done.\u001b[K\n","remote: Total 208 (delta 45), reused 40 (delta 40), pack-reused 159 (from 1)\u001b[K\n","Receiving objects: 100% (208/208), 1.20 MiB | 15.60 MiB/s, done.\n","Resolving deltas: 100% (76/76), done.\n"]}]},{"cell_type":"markdown","source":["sort í•¨ìˆ˜ (ìˆ˜ì • ì „)"],"metadata":{"id":"ubii24R__PEf"}},{"cell_type":"code","source":["%%writefile /content/sort_tracker.py\n","# =====================================================\n","# SORT: Simple Online and Realtime Tracking\n","# Source adapted from https://github.com/abewley/sort\n","# =====================================================\n","\n","import numpy as np\n","from filterpy.kalman import KalmanFilter\n","from scipy.optimize import linear_sum_assignment\n","\n","\n","def iou(bb_test, bb_gt):\n","    xx1 = np.maximum(bb_test[0], bb_gt[0])\n","    yy1 = np.maximum(bb_test[1], bb_gt[1])\n","    xx2 = np.minimum(bb_test[2], bb_gt[2])\n","    yy2 = np.minimum(bb_test[3], bb_gt[3])\n","    w = np.maximum(0., xx2 - xx1)\n","    h = np.maximum(0., yy2 - yy1)\n","    wh = w * h\n","    o = wh / (\n","        (bb_test[2] - bb_test[0]) * (bb_test[3] - bb_test[1]) +\n","        (bb_gt[2] - bb_gt[0]) * (bb_gt[3] - bb_gt[1]) - wh\n","    )\n","    return o\n","\n","\n","class KalmanBoxTracker:\n","    count = 0\n","\n","    def __init__(self, bbox):\n","        self.kf = KalmanFilter(dim_x=7, dim_z=4)\n","        self.kf.F = np.array(\n","            [[1,0,0,0,1,0,0],\n","            [0,1,0,0,0,1,0],\n","            [0,0,1,0,0,0,1],\n","            [0,0,0,1,0,0,0],\n","            [0,0,0,0,1,0,0],\n","            [0,0,0,0,0,1,0],\n","            [0,0,0,0,0,0,1]]\n","        )\n","        self.kf.H = np.array([\n","            [1,0,0,0,0,0,0],\n","            [0,1,0,0,0,0,0],\n","            [0,0,1,0,0,0,0],\n","            [0,0,0,1,0,0,0]\n","        ])\n","        self.kf.R[2:,2:] *= 10.\n","        self.kf.P[4:,4:] *= 1000.\n","        self.kf.P *= 10.\n","        self.kf.Q[-1,-1] *= 0.01\n","        self.kf.Q[4:,4:] *= 0.01\n","\n","        # Fix: only take first 4 elements (coords)\n","        self.kf.x[:4] = bbox[:4].reshape((4,1))\n","        self.time_since_update = 0\n","        self.id = KalmanBoxTracker.count\n","        KalmanBoxTracker.count += 1\n","        self.history = []\n","        self.hits = 0\n","        self.hit_streak = 0\n","        self.age = 0\n","\n","    def update(self, bbox):\n","        self.time_since_update = 0\n","        self.history = []\n","        self.hits += 1\n","        self.hit_streak += 1\n","        # Fix: only take first 4 elements (coords)\n","        self.kf.update(bbox[:4].reshape((4,1)))\n","\n","    def predict(self):\n","        if (self.kf.x[6] + self.kf.x[2]) <= 0:\n","            self.kf.x[6] *= 0.0\n","        self.kf.predict()\n","        self.age += 1\n","        if self.time_since_update > 0:\n","            self.hit_streak = 0\n","        self.time_since_update += 1\n","        self.history.append(self.kf.x)\n","        return self.kf.x\n","\n","\n","class Sort:\n","    def __init__(self, max_age=5, min_hits=2, iou_threshold=0.3):\n","        self.max_age = max_age\n","        self.min_hits = min_hits\n","        self.iou_threshold = iou_threshold\n","        self.trackers = []\n","        self.frame_count = 0\n","\n","    def update(self, dets=np.empty((0,4))):\n","        self.frame_count += 1\n","\n","        trks = np.zeros((len(self.trackers), 4))\n","        to_del = []\n","        for t, trk in enumerate(self.trackers):\n","            pos = trk.predict()\n","            trks[t] = pos[:4].reshape((1,4))\n","            if np.any(np.isnan(pos)):\n","                to_del.append(t)\n","        trks = np.ma.compress_rows(np.ma.masked_invalid(trks))\n","        for t in reversed(to_del):\n","            self.trackers.pop(t)\n","\n","        matched, unmatched_dets, unmatched_trks = associate_detections_to_trackers(\n","            dets, trks, self.iou_threshold\n","        )\n","\n","        for m in matched:\n","            self.trackers[m[1]].update(dets[m[0]])\n","\n","        for i in unmatched_dets:\n","            self.trackers.append(KalmanBoxTracker(dets[i]))\n","\n","        ret = []\n","        for trk in self.trackers:\n","            if trk.time_since_update < 1 and (trk.hits >= self.min_hits or self.frame_count <= self.min_hits):\n","                ret.append(np.concatenate((trk.kf.x[:4].reshape((1,4)), [[trk.id]]), axis=1))\n","        return np.concatenate(ret) if len(ret) > 0 else np.empty((0,5))\n","\n","\n","def associate_detections_to_trackers(detections, trackers, iou_threshold):\n","    if len(trackers) == 0:\n","        return np.empty((0,2), dtype=int), np.arange(len(detections)), np.empty((0), dtype=int)\n","\n","    iou_matrix = np.zeros((len(detections), len(trackers)), dtype=np.float32)\n","    for d, det in enumerate(detections):\n","        for t, trk in enumerate(trackers):\n","            iou_matrix[d,t] = iou(det, trk)\n","\n","    matched_indices = linear_sum_assignment(-iou_matrix)\n","    matched_indices = np.array(list(zip(*matched_indices)))\n","\n","    # Fix for IndexError when matched_indices is empty\n","    if len(matched_indices) == 0:\n","        matched_indices = np.empty((0, 2), dtype=int)\n","\n","    unmatched_detections = []\n","    for d in range(len(detections)):\n","        if d not in matched_indices[:,0]:\n","            unmatched_detections.append(d)\n","\n","    unmatched_trackers = []\n","    for t in range(len(trackers)):\n","        if t not in matched_indices[:,1]:\n","            unmatched_trackers.append(t)\n","\n","    matches = []\n","    for m in matched_indices:\n","        if iou_matrix[m[0], m[1]] < iou_threshold:\n","            unmatched_detections.append(m[0])\n","            unmatched_trackers.append(m[1])\n","        else:\n","            matches.append(m.reshape(1,2))\n","\n","    if len(matches) == 0:\n","        matches = np.empty((0,2), dtype=int)\n","    else:\n","        matches = np.concatenate(matches, axis=0)\n","\n","    return matches, np.array(unmatched_detections), np.array(unmatched_trackers)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FvVcls0UMriJ","outputId":"d4c3fcb9-b826-4540-9c9b-7148cc699bd9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/sort_tracker.py\n"]}]},{"cell_type":"markdown","source":["ìˆ˜ì •í•œ sort í•¨ìˆ˜"],"metadata":{"id":"4D6yKhP1BZPW"}},{"cell_type":"code","source":["%%writefile /content/sort_tracker.py\n","# =====================================================\n","# SORT: Simple Online and Realtime Tracking\n","# Source adapted from https://github.com/abewley/sort\n","# =====================================================\n","\n","import numpy as np\n","from filterpy.kalman import KalmanFilter\n","from scipy.optimize import linear_sum_assignment\n","\n","\n","def iou(bb_test, bb_gt):\n","    xx1 = np.maximum(bb_test[0], bb_gt[0])\n","    yy1 = np.maximum(bb_test[1], bb_gt[1])\n","    xx2 = np.minimum(bb_test[2], bb_gt[2])\n","    yy2 = np.minimum(bb_test[3], bb_gt[3])\n","    w = np.maximum(0., xx2 - xx1)\n","    h = np.maximum(0., yy2 - yy1)\n","    wh = w * h\n","    o = wh / (\n","        (bb_test[2] - bb_test[0]) * (bb_test[3] - bb_test[1]) +\n","        (bb_gt[2] - bb_gt[0]) * (bb_gt[3] - bb_gt[1]) - wh\n","    )\n","    return o\n","\n","\n","class KalmanBoxTracker:\n","    count = 0\n","\n","    def __init__(self, bbox):\n","        # 7ê°œ ìƒíƒœ ë³€ìˆ˜: [u, v, s, r, u', v', s']\n","        # u,v: ì¤‘ì‹¬ì , s: ì˜ì—­(ë„“ì´), r: ê°€ë¡œì„¸ë¡œë¹„\n","        self.kf = KalmanFilter(dim_x=7, dim_z=4)\n","        self.kf.F = np.array(\n","            [[1,0,0,0,1,0,0],\n","             [0,1,0,0,0,1,0],\n","             [0,0,1,0,0,0,1],\n","             [0,0,0,1,0,0,0],\n","             [0,0,0,0,1,0,0],\n","             [0,0,0,0,0,1,0],\n","             [0,0,0,0,0,0,1]]\n","        )\n","        self.kf.H = np.array([\n","            [1,0,0,0,0,0,0],\n","            [0,1,0,0,0,0,0],\n","            [0,0,1,0,0,0,0],\n","            [0,0,0,1,0,0,0]\n","        ])\n","\n","        # --- [ê°œì„  í¬ì¸íŠ¸: ë…¸ì´ì¦ˆ íŒŒë¼ë¯¸í„° ìµœì í™”] ---\n","        # R: ê´€ì¸¡ ë…¸ì´ì¦ˆ. YOLO ë°•ìŠ¤ì˜ ë¯¸ì„¸í•œ ë–¨ë¦¼ì„ ë” ë§ì´ ë¬´ì‹œí•˜ë„ë¡ ìƒí–¥ ì¡°ì • (10 -> 20~30)\n","        self.kf.R[2:, 2:] *= 20.0\n","\n","        # P: ì´ˆê¸° ì˜¤ì°¨ ê³µë¶„ì‚°. ì´ˆê¸° ìœ„ì¹˜ëŠ” í™•ì‹¤ì¹˜ ì•Šìœ¼ë¯€ë¡œ í¬ê²Œ ì„¤ì •\n","        self.kf.P[4:, 4:] *= 1000.\n","        self.kf.P *= 10.\n","\n","        # Q: í”„ë¡œì„¸ìŠ¤ ë…¸ì´ì¦ˆ.\n","        # ì†ë„(u', v') í•­ì˜ ë³€í™”ë¥¼ ì–µì œí•˜ì—¬ ê¶¤ì ì„ ë” ì§ì„ ì ì´ê³  ë¶€ë“œëŸ½ê²Œ ë§Œë“¦\n","        self.kf.Q[-1, -1] *= 0.001\n","        self.kf.Q[4:, 4:] *= 0.001\n","        # ------------------------------------------\n","\n","        # bbox ì •ë³´ë¥¼ ìƒíƒœ ë³€ìˆ˜ë¡œ ë³€í™˜ (u, v, s, r)\n","        w = bbox[2] - bbox[0]\n","        h = bbox[3] - bbox[1]\n","        u = bbox[0] + w/2.\n","        v = bbox[1] + h/2.\n","        s = w * h\n","        r = w / float(h)\n","        self.kf.x[:4] = np.array([u, v, s, r]).reshape((4, 1))\n","\n","        self.time_since_update = 0\n","        self.id = KalmanBoxTracker.count\n","        KalmanBoxTracker.count += 1\n","        self.history = []\n","        self.hits = 0\n","        self.hit_streak = 0\n","        self.age = 0\n","\n","    def update(self, bbox):\n","        self.time_since_update = 0\n","        self.history = []\n","        self.hits += 1\n","        self.hit_streak += 1\n","\n","        # ì…ë ¥ë°›ì€ [x1, y1, x2, y2]ë¥¼ [u, v, s, r]ë¡œ ë³€í™˜í•˜ì—¬ ì—…ë°ì´íŠ¸\n","        w = bbox[2] - bbox[0]\n","        h = bbox[3] - bbox[1]\n","        u = bbox[0] + w/2.\n","        v = bbox[1] + h/2.\n","        s = w * h\n","        r = w / float(h)\n","        self.kf.update(np.array([u, v, s, r]).reshape((4, 1)))\n","\n","    def predict(self):\n","        \"\"\"\n","        Kalman filterì˜ ë‹¤ìŒ ìƒíƒœë¥¼ ì˜ˆì¸¡í•˜ê³ , ì˜ˆì¸¡ëœ ìƒíƒœë¥¼ [x1, y1, x2, y2] í˜•íƒœë¡œ ë°˜í™˜\n","        \"\"\"\n","        if (self.kf.x[6] + self.kf.x[2]) <= 0:\n","            self.kf.x[6] *= 0.0 # Prevent negative width/height\n","        self.kf.predict()\n","        self.age += 1\n","        if self.time_since_update > 0:\n","            self.hit_streak = 0\n","        self.time_since_update += 1\n","\n","        # Get the predicted state and convert it to bbox format [x1, y1, x2, y2]\n","        # The `get_state` method already does this conversion\n","        predicted_bbox = self.get_state()\n","        self.history.append(predicted_bbox) # Store bbox, not raw kf.x\n","        return predicted_bbox\n","\n","    def get_state(self):\n","        \"\"\"\n","        [u, v, s, r] ìƒíƒœë¥¼ [x1, y1, x2, y2] í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜\n","        \"\"\"\n","        x = self.kf.x\n","        # Ensure s (area) and r (aspect ratio) are positive before sqrt\n","        s_val = max(0.01, x[2][0]) # Ensure area is not zero or negative\n","        r_val = max(0.01, x[3][0]) # Ensure aspect ratio is not zero or negative\n","\n","        w = np.sqrt(s_val * r_val)\n","        h = s_val / w\n","\n","        # Calculate x1, y1, x2, y2 from center (u,v), width (w), height (h)\n","        return np.array([x[0][0] - w/2., x[1][0] - h/2., x[0][0] + w/2., x[1][0] + h/2.]).reshape((1, 4))\n","\n","\n","class Sort:\n","    def __init__(self, max_age=5, min_hits=2, iou_threshold=0.3):\n","        self.max_age = max_age\n","        self.min_hits = min_hits\n","        self.iou_threshold = iou_threshold\n","        self.trackers = []\n","        self.frame_count = 0\n","\n","    def update(self, dets=np.empty((0,4))):\n","        self.frame_count += 1\n","\n","        trks = np.zeros((len(self.trackers), 4)) # To store predicted bboxes from trackers\n","        to_del = []\n","        for t, trk in enumerate(self.trackers):\n","            pos = trk.predict() # This calls the new predict method\n","            trks[t] = pos.reshape((1,4)) # predict now returns the bbox directly\n","            if np.any(np.isnan(pos)) or pos[0,2] <= pos[0,0] or pos[0,3] <= pos[0,1]: # Check for invalid bboxes\n","                to_del.append(t)\n","\n","        # Remove invalid trackers before association\n","        for t in reversed(to_del):\n","            self.trackers.pop(t)\n","        trks = np.delete(trks, to_del, axis=0)\n","\n","        matched, unmatched_dets, unmatched_trks = associate_detections_to_trackers(\n","            dets, trks, self.iou_threshold\n","        )\n","\n","        for m in matched:\n","            self.trackers[m[1]].update(dets[m[0]])\n","\n","        for i in unmatched_dets:\n","            self.trackers.append(KalmanBoxTracker(dets[i]))\n","\n","        ret = []\n","        for trk_idx, trk in enumerate(self.trackers):\n","            if trk.time_since_update < 1 and (trk.hits >= self.min_hits or self.frame_count <= self.min_hits):\n","                # Use the current state from the tracker (which is in bbox format after update/predict)\n","                current_bbox = trk.get_state() # Use get_state to get the current bbox\n","                ret.append(np.concatenate((current_bbox, [[trk.id]]), axis=1))\n","\n","            # Delete old trackers\n","            if trk.time_since_update > self.max_age:\n","                to_del.append(trk_idx)\n","\n","        # Delete trackers that have exceeded max_age\n","        for t in reversed(to_del):\n","            if t < len(self.trackers):\n","                self.trackers.pop(t)\n","\n","        return np.concatenate(ret) if len(ret) > 0 else np.empty((0,5))\n","\n","\n","def associate_detections_to_trackers(detections, trackers, iou_threshold):\n","    if len(trackers) == 0:\n","        return np.empty((0,2), dtype=int), np.arange(len(detections)), np.empty((0), dtype=int)\n","\n","    iou_matrix = np.zeros((len(detections), len(trackers)), dtype=np.float32)\n","    for d, det in enumerate(detections):\n","        for t, trk in enumerate(trackers):\n","            iou_matrix[d,t] = iou(det, trk) # det and trk are now both [x1, y1, x2, y2]\n","\n","    matched_indices = linear_sum_assignment(-iou_matrix)\n","    matched_indices = np.array(list(zip(*matched_indices)))\n","\n","    # Fix for IndexError when matched_indices is empty\n","    if len(matched_indices) == 0:\n","        matched_indices = np.empty((0, 2), dtype=int)\n","\n","    unmatched_detections = []\n","    for d in range(len(detections)):\n","        if d not in matched_indices[:,0]:\n","            unmatched_detections.append(d)\n","\n","    unmatched_trackers = []\n","    for t in range(len(trackers)):\n","        if t not in matched_indices[:,1]:\n","            unmatched_trackers.append(t)\n","\n","    matches = []\n","    for m in matched_indices:\n","        if iou_matrix[m[0], m[1]] < iou_threshold:\n","            unmatched_detections.append(m[0])\n","            unmatched_trackers.append(m[1])\n","        else:\n","            matches.append(m.reshape(1,2))\n","\n","    if len(matches) == 0:\n","        matches = np.empty((0,2), dtype=int)\n","    else:\n","        matches = np.concatenate(matches, axis=0)\n","\n","    return matches, np.array(unmatched_detections), np.array(unmatched_trackers)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y51mE8PhBsxR","executionInfo":{"status":"ok","timestamp":1768459678732,"user_tz":-540,"elapsed":19,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}},"outputId":"9d7017bd-387c-4c89-b527-a828ead9d632"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/sort_tracker.py\n"]}]},{"cell_type":"markdown","source":["ë§Œë“¤ì–´ì§„ sort í•¨ìˆ˜ ì €ì¥í•˜ê¸°"],"metadata":{"id":"wd9mqbQB_Zgg"}},{"cell_type":"code","source":["import sys\n","sys.path.insert(0, \"/content\")\n","\n","from sort_tracker import Sort\n","\n","tracker = Sort()\n","print(\"SORT import OK\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ny9L6FNoMr50","outputId":"a062296b-aa9a-4081-d02f-46cac3158fef","executionInfo":{"status":"ok","timestamp":1768459699727,"user_tz":-540,"elapsed":51,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}}},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["SORT import OK\n"]}]},{"cell_type":"code","source":["import cv2\n","import os\n","import glob\n","import numpy as np\n","import imageio\n","from collections import deque\n","from tqdm import tqdm"],"metadata":{"id":"nRJrtCv0Mr9_","executionInfo":{"status":"ok","timestamp":1768459701055,"user_tz":-540,"elapsed":12,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}}},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":["RiskManager(ìˆ˜ì • ì „)"],"metadata":{"id":"HzDWIDCN_Js-"}},{"cell_type":"code","source":["class IntentAwareRiskManager:\n","    def __init__(self, window_size=5):\n","        self.window_size = window_size\n","        self.history = {}  # {track_id: deque[(cx, cy)]}\n","\n","    def _update_history(self, track_id, center):\n","        if track_id not in self.history:\n","            self.history[track_id] = deque(maxlen=self.window_size)\n","        self.history[track_id].append(center)\n","\n","    def _is_long_static(self, centers, move_thresh=3.0, min_static_frames=6):\n","        if len(centers) < min_static_frames + 1:\n","            return False\n","\n","        diffs = [\n","            np.linalg.norm(np.array(centers[i]) - np.array(centers[i-1]))\n","            for i in range(1, len(centers))\n","        ]\n","        return all(d < move_thresh for d in diffs[-min_static_frames:])\n","\n","    def _compute_2d_traj_metrics(self, centers, fps, img_w, img_h, eps=1e-3):\n","        \"\"\"\n","        return: ttc, v_rel, d_curr\n","        \"\"\"\n","        if len(centers) < 2:\n","            return float('inf'), 0.0, float('inf')\n","\n","        ego = np.array([img_w / 2, img_h])\n","        p_prev = np.array(centers[-2])\n","        p_curr = np.array(centers[-1])\n","\n","        d_prev = np.linalg.norm(p_prev - ego)\n","        d_curr = np.linalg.norm(p_curr - ego)\n","        v_rel = (d_prev - d_curr) * fps  # px/sec\n","\n","        # ì ‘ê·¼ ì•ˆ í•˜ë©´ ë¬´íš¨\n","        if v_rel < 5.0:\n","            return float('inf'), v_rel, d_curr\n","\n","        # ì¥ê¸° ì •ì§€ í•„í„°\n","        if self._is_long_static(centers):\n","            return float('inf'), v_rel, d_curr\n","\n","        ttc = d_curr / max(v_rel, eps)\n","        return ttc, v_rel, d_curr\n","\n","    def calculate_risk(self, track_id, bbox, location, actions, fps, img_w, img_h):\n","        cx = (bbox[0] + bbox[2]) / 2\n","        cy = (bbox[1] + bbox[3]) / 2\n","        self._update_history(track_id, (cx, cy))\n","        centers = self.history[track_id]\n","\n","        # --- Step 1: Physical risk ---\n","        ttc, v_rel, d_curr = self._compute_2d_traj_metrics(\n","            centers, fps, img_w, img_h\n","        )\n","\n","        base_score = 0.0\n","        if ttc < 5.0:\n","            base_score = min(50.0, 50.0 * (3.0 / max(ttc, 0.5)))\n","\n","        # --- Step 2: Semantic reasoning ---\n","        semantic_bonus = 0.0\n","        omega = 1.0\n","        reason = \"Normal\"\n","\n","        # Ignore irrelevant zones\n","        if location in [2, 3, 4]:\n","            return {\n","                \"score\": 0.0,\n","                \"ttc\": \"Safe\",\n","                \"reason\": \"Ignored\",\n","                \"level\": \"SAFE\"\n","            }\n","\n","        HIGH_SPEED = 80.0  # px/sec\n","\n","        # Ego lane\n","        if location == 0:\n","            if ttc < 2.0 and v_rel > HIGH_SPEED:\n","                reason = \"Rapid Approach\"\n","                semantic_bonus = 10.0\n","            elif ttc < 2.0:\n","                reason = \"Close Following\"\n","            else:\n","                reason = \"Normal Deceleration\"\n","\n","        # Adjacent lane (cut-in)\n","        elif location == 1:\n","            if actions[1] == 1 or actions[2] == 1:\n","                reason = \"Dangerous Cut-in\"\n","                semantic_bonus = 10.0\n","                omega = 1.3\n","            else:\n","                reason = \"Approaching\"\n","                omega = 0.8\n","\n","        final_risk = min(base_score * omega + semantic_bonus, 100.0)\n","\n","        return {\n","            \"score\": round(final_risk, 2),\n","            \"ttc\": round(ttc, 2) if ttc != float('inf') else \"Safe\",\n","            \"reason\": reason,\n","            \"level\": self._get_risk_level(final_risk),\n","        }\n","\n","    def _get_risk_level(self, score):\n","        if score > 50: return \"DANGER\"\n","        if score > 20: return \"WARNING\"\n","        return \"SAFE\"\n"],"metadata":{"id":"bkSbCaxyMsAl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ìˆ˜ì •í•œ ë²„ì „ RiskManager"],"metadata":{"id":"VnEcPTRX_Gia"}},{"cell_type":"code","source":["import numpy as np\n","from collections import deque\n","\n","class IntentAwareRiskManager:\n","    def __init__(self, window_size=10):\n","        self.window_size = window_size\n","        self.history = {} # {tid: deque([d1, d2, ...])}\n","\n","    def calculate_risk(self, track_id, bbox, location, actions, fps, img_w, img_h):\n","        # 1. ìì°¨ ìœ„ì¹˜ ì •ì˜ (p_ego)\n","        ego_p = np.array([img_w / 2, img_h])\n","\n","        # 2. ê°ì²´ ì¤‘ì‹¬ì  ì¶”ì¶œ (c_x, c_y)\n","        curr_p = np.array([(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2])\n","\n","        # 3. ê±°ë¦¬ ê³„ì‚° (ì›ê·¼ ì™œê³¡ ë³´ì •ì„ ìœ„í•œ y ê°€ì¤‘ì¹˜ ê³ ë ¤ ê¶Œì¥)\n","        # ì—¬ê¸°ì„œëŠ” ë…¼ë¬¸ ìˆ˜ì‹ëŒ€ë¡œ ìœ í´ë¦¬ë“œ ê±°ë¦¬ d_t ê³„ì‚°\n","        d_t = np.linalg.norm(curr_p - ego_p)\n","\n","        if track_id not in self.history:\n","            self.history[track_id] = deque(maxlen=self.window_size)\n","        self.history[track_id].append(d_t)\n","\n","        # --- Step 1: v_rel ë° TTC ê³„ì‚° (ì „ëµ 2 ì ìš©) ---\n","        d_history = list(self.history[track_id])\n","        if len(d_history) < 3:\n","            return self._safe_response()\n","\n","        # ë‹¨ìˆœ ì°¨ì´ ëŒ€ì‹  ì„ í˜• íšŒê·€ë¡œ ê¸°ìš¸ê¸°(v_rel) ì¶”ì¶œ\n","        x = np.arange(len(d_history))\n","        slope, _ = np.polyfit(x, d_history, 1)\n","        v_rel = -slope * fps  # ê±°ë¦¬ê°€ ì¤„ì–´ë“¤ë©´ slopeëŠ” ìŒìˆ˜ì´ë¯€ë¡œ -ë¥¼ ë¶™ì—¬ ì ‘ê·¼ ì†ë„ë¡œ ë³€í™˜\n","\n","        # ì ‘ê·¼ ì†ë„ ì„ê³„ê°’ í•„í„°ë§ (v_rel < threshold)\n","        if v_rel < 5.0:\n","            return self._safe_response()\n","\n","        # TTC ê³„ì‚°\n","        ttc = d_t / max(v_rel, 1e-3)\n","\n","        # --- Step 2: Base Risk Score (ìˆ˜ì‹ ì ìš©) ---\n","        base_score = 0.0\n","        if ttc < 5.0:\n","            # Score_base = min(50, 50 * (3 / max(TTC, 0.5)))\n","            base_score = min(50.0, 50.0 * (3.0 / max(ttc, 0.5)))\n","\n","        # --- Step 3: Semantic Risk Amplification ---\n","        if location in [2, 3, 4]: # ë„ë¡œ ë¬¸ë§¥ í•„í„°ë§\n","            return self._safe_response(\"Ignored Zone\")\n","\n","        omega = 1.0\n","        bonus = 0.0\n","        reason = \"Normal\"\n","\n","        if location == 0: # ì£¼í–‰ ì°¨ë¡œ (Ego Lane)\n","            if ttc < 2.0 and v_rel > 80.0: # ì„ê³„ê°’ì€ í”½ì…€ ì†ë„ ê¸°ì¤€ íŠœë‹ í•„ìš”\n","                reason = \"Rapid Approach\"\n","                bonus = 15.0\n","                omega = 1.2\n","            elif ttc < 2.0:\n","                reason = \"Close Following\"\n","                bonus = 5.0\n","            else:\n","                reason = \"Normal Deceleration\"\n","\n","        elif location == 1: # ì¸ì ‘ ì°¨ë¡œ (Adjacent)\n","            if actions[1] == 1 or actions[2] == 1: # ë°©í–¥ ì§€ì‹œë“± í™œì„±í™”\n","                reason = \"Dangerous Cut-in\"\n","                omega = 1.5\n","                bonus = 20.0\n","            else:\n","                reason = \"Approaching\"\n","                omega = 0.8\n","\n","        # --- ìµœì¢… ì ìˆ˜ ì‚°ì¶œ ---\n","        final_score = min(base_score * omega + bonus, 100.0)\n","\n","        return {\n","            \"score\": round(final_score, 2),\n","            \"ttc\": round(ttc, 2),\n","            \"reason\": reason,\n","            \"level\": self._get_risk_level(final_score)\n","        }\n","\n","    def _get_risk_level(self, score):\n","        if score >= 50: return \"DANGER\"\n","        elif score >= 25: return \"WARNING\"\n","        #elif score >= 30: return \"CAUTION\"\n","        else: return \"SAFE\"\n","\n","    def _safe_response(self, reason=\"Safe\"):\n","        return {\"score\": 0.0, \"ttc\": \"Safe\", \"reason\": reason, \"level\": \"SAFE\"}"],"metadata":{"id":"evr6bwAb_ICw","executionInfo":{"status":"ok","timestamp":1768461511817,"user_tz":-540,"elapsed":50,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}}},"execution_count":85,"outputs":[]},{"cell_type":"markdown","source":["(XXX ì•„ë˜ê±° ì‹¤í–‰!!) sort, RiskManager í†µí•© ì‹¤í–‰ ìˆ˜ì •ë²„ì „ (ì˜ìƒìœ¼ë¡œ ì €ì¥) (íŠ¹ì • íŒŒì¼ë§Œ ì €ì¥)"],"metadata":{"id":"Fe1nAEAeHUDu"}},{"cell_type":"code","source":["import pandas as pd\n","import cv2\n","import os\n","import numpy as np\n","from tqdm import tqdm\n","\n","# Sort íŠ¸ë˜ì»¤ì—ì„œ iou í•¨ìˆ˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n","import importlib\n","import sort_tracker\n","importlib.reload(sort_tracker) # Reload the module to ensure latest changes are applied\n","from sort_tracker import Sort, iou\n","\n","# 1. ë¨¼ì € CSV íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤. (ê²½ë¡œëŠ” ë³¸ì¸ì˜ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)\n","DET_CSV_PATH = \"/content/Capture_SafeDrive_T4_HighPerf/test_sequences_combined/bb_1_140613_vehicle_224_55460_mp4_20260114/bb_1_140613_vehicle_224_55460_mp4_20260114_analysis.csv\"\n","all_det_df = pd.read_csv(DET_CSV_PATH)\n","\n","# OUTPUT_ROOT_RISK ë³€ìˆ˜ ì •ì˜ ì¶”ê°€\n","OUTPUT_ROOT_RISK = \"/content/Capture_SafeDrive_T4_HighPerf/risk_video\"\n","\n","# RISK_COLORS ì •ì˜ ì¶”ê°€ (ì´ì „ ì…€ì—ì„œ ì •ì˜ë˜ì—ˆìœ¼ë‚˜ ëª…í™•ì„±ì„ ìœ„í•´ ì¶”ê°€)\n","RISK_COLORS = {\n","    \"SAFE\": (0, 255, 0),       # Green\n","    \"WARNING\": (0, 165, 255),  # Orange\n","    \"DANGER\": (0, 0, 255),\n","    \"CAUTION\": (0, 255, 255) # Yellow\n","}\n","\n","\"\"\"\n","def process_sequence_from_csv(seq_name, image_paths, output_dir, det_df):\n","    os.makedirs(output_dir, exist_ok=True)\n","    video_path = os.path.join(output_dir, f\"{seq_name}_risk_analysis.mp4\")\n","\n","    image_paths = sorted(image_paths)\n","    if not image_paths: return\n","\n","    # Init Tracker & Risk Manager\n","    tracker = Sort(max_age=5, min_hits=1, iou_threshold=0.3)\n","    risk_manager = IntentAwareRiskManager(window_size=10)\n","\n","    # Video Writer Init\n","    sample_img = cv2.imread(image_paths[0])\n","    h, w = sample_img.shape[:2]\n","    fps = 10.0\n","    out = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n","\n","    print(f\"ğŸ¬ Processing {seq_name} from CSV...\")\n","\n","    # í•´ë‹¹ ì‹œí€€ìŠ¤ ë°ì´í„°ë§Œ í•„í„°ë§\n","    # NOTE: 'frame' ì»¬ëŸ¼ì´ ì—†ìœ¼ë¯€ë¡œ 'Filename'ì„ ê¸°ë°˜ìœ¼ë¡œ í•„í„°ë§í•˜ë„ë¡ ìˆ˜ì •\n","    seq_data = det_df[det_df['Filename'].apply(lambda x: x.startswith(seq_name))].copy()\n","    seq_data['frame'] = seq_data['Filename'].apply(lambda x: int(os.path.basename(x).split('_')[-1].replace('.png', '')))\n","\n","    for frame_idx, img_path in enumerate(tqdm(image_paths, leave=False)):\n","        img_cv = cv2.imread(img_path)\n","        if img_cv is None: continue\n","\n","        # --- [ë³€ê²½ íŒŒíŠ¸ 1: ëª¨ë¸ í˜¸ì¶œ ëŒ€ì‹  CSV í•„í„°ë§] ---\n","        # í˜„ì¬ í”„ë ˆì„ì— í•´ë‹¹í•˜ëŠ” ê²€ì¶œ ë°ì´í„° ì¶”ì¶œ\n","        frame_filename = os.path.basename(img_path)\n","        current_frame_dets = seq_data[seq_data['Filename'] == frame_filename].copy()\n","\n","        # SORT ì…ë ¥ì„ ìœ„í•´ [x1, y1, x2, y2, conf] í˜•íƒœë¡œ ë³€í™˜ (confëŠ” CSVì— ì—†ìœ¼ë¯€ë¡œ ì„ì‹œë¡œ 1.0 ì‚¬ìš©)\n","        # CSVì— confê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ 1.0ìœ¼ë¡œ ì„ì‹œ ì„¤ì •. ì‹¤ì œ conf ê°’ì´ ìˆë‹¤ë©´ í•´ë‹¹ ì»¬ëŸ¼ ì‚¬ìš©\n","        if 'conf' not in current_frame_dets.columns:\n","            current_frame_dets['conf'] = 1.0\n","        dets_to_sort = current_frame_dets[['x1', 'y1', 'x2', 'y2', 'conf']].values\n","\n","        # 2. SORT Tracking (ê¸°ì¡´ê³¼ ë™ì¼)\n","        track_dets = tracker.update(dets_to_sort)\n","\n","        # 3. ìœ„í—˜ë„ ê³„ì‚° (ê¸°ì¡´ ROI ëª¨ë¸ í˜¸ì¶œë¶€ ì‚­ì œ)\n","        if len(track_dets) > 0:\n","            for trk in track_dets:\n","                x1, y1, x2, y2, track_id = trk\n","\n","                # --- [ë³€ê²½ íŒŒíŠ¸ 2: CSVì—ì„œ ì˜ë¯¸ ì •ë³´(loc, action) ë§¤ì¹­] ---\n","                # íŠ¸ë˜í‚¹ëœ ë°•ìŠ¤ì™€ ê°€ì¥ ê°€ê¹Œìš´ ì›ë³¸ CSV ë°•ìŠ¤ ì°¾ê¸°\n","                if len(current_frame_dets) > 0:\n","                    # YOLOì˜ ë°•ìŠ¤ì™€ SORTì˜ íŠ¸ë™í‚¹ëœ ë°•ìŠ¤ ê°„ì˜ IoUë¥¼ ê³„ì‚°í•˜ì—¬ ë§¤ì¹­\n","                    matched_iou_val = -1\n","                    matched_row = None\n","                    for _, det_row in current_frame_dets.iterrows():\n","                        iou_val = iou(trk[:4], det_row[['x1', 'y1', 'x2', 'y2']].values)\n","                        if iou_val > matched_iou_val and iou_val > 0.1: # IoU ì„ê³„ê°’ ì„¤ì •\n","                            matched_iou_val = iou_val\n","                            matched_row = det_row\n","\n","                    if matched_row is not None:\n","                        loc_idx = int(matched_row['Location_ID'])\n","                        # CSV ì»¬ëŸ¼ëª…ì— ë”°ë¼ act_brake, act_left ë“±ìœ¼ë¡œ êµ¬ì„±ëœ ê°’ì„ ë°°ì—´ë¡œ ë§Œë“¦\n","                        is_active = matched_row[['Brake', 'Left', 'Right', 'Hazard']].values.astype(int)\n","\n","                        # 4. Risk Calculation (ê¸°ì¡´ê³¼ ë™ì¼)\n","                        risk_result = risk_manager.calculate_risk(\n","                            track_id=int(track_id),\n","                            bbox=[x1, y1, x2, y2],\n","                            location=loc_idx,\n","                            actions=is_active,\n","                            fps=fps, img_w=w, img_h=h\n","                        )\n","\n","                        # 5. ì‹œê°í™” (ê¸°ì¡´ê³¼ ë™ì¼)\n","                        level = risk_result[\"level\"]\n","                        color = RISK_COLORS.get(level, (0, 255, 0))\n","                        cv2.rectangle(img_cv, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n","\n","                        loc_names = [\"My\", \"Next\", \"Opposite\", \"RoadSide\", \"None\"]\n","                        info_text = f\"ID:{int(track_id)} | {loc_names[loc_idx] if loc_idx < len(loc_names) else '??'}\"\n","                        cv2.putText(img_cv, info_text, (int(x1), int(y1) - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n","                        cv2.putText(img_cv, f\"{level} ({risk_result['score']})\", (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n","\n","                        if level != \"SAFE\":\n","                            cv2.putText(img_cv, risk_result[\"reason\"], (int(x1), int(y2) + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n","\n","        out.write(img_cv)\n","\n","    out.release()\n","\n","\"\"\"\n","# --- ì‹¤í–‰ ë¶€ë¶„ ---\n","for seq_name, img_list in sequences.items():\n","    process_sequence_from_csv(\n","        seq_name,\n","        img_list,\n","        OUTPUT_ROOT_RISK,\n","        all_det_df  # ëª¨ë¸ ëŒ€ì‹  ë°ì´í„°í”„ë ˆì„ ì „ë‹¬\n","    )\n","    \"\"\"\n","\n","# --- ì‹¤í–‰ ë¶€ë¶„ ---\n","\n","# 1. CSV íŒŒì¼ ì•ˆì— ì–´ë–¤ ì‹œí€€ìŠ¤ ì´ë¦„ë“¤ì´ ìˆëŠ”ì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n","# Filename ì»¬ëŸ¼ì˜ ê°’(ì˜ˆ: 'CounterClock2_Fog_001.png')ì—ì„œ ì‹œí€€ìŠ¤ ì´ë¦„ë§Œ ë½‘ì•„ëƒ…ë‹ˆë‹¤.\n","csv_sequence_names = all_det_df['Filename'].apply(lambda x: x.rsplit('_', 1)[0]).unique()\n","\n","print(f\"âœ… CSVì— í¬í•¨ëœ ì‹œí€€ìŠ¤ ëª©ë¡: {csv_sequence_names}\")\n","\n","for seq_name, img_list in sequences.items():\n","    # 2. í˜„ì¬ ì²˜ë¦¬í•˜ë ¤ëŠ” í´ë”ëª…(seq_name)ì´ CSV ë¦¬ìŠ¤íŠ¸ì— ë“¤ì–´ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n","    if seq_name in csv_sequence_names:\n","        process_sequence_from_csv(\n","            seq_name,\n","            img_list,\n","            OUTPUT_ROOT_RISK,\n","            all_det_df\n","        )\n","    else:\n","        # CSVì— ì •ë³´ê°€ ì—†ëŠ” í´ë”ëŠ” ê·¸ëƒ¥ ê±´ë„ˆëœë‹ˆë‹¤.\n","        print(f\"â© Skipping {seq_name}: No matching data found in CSV.\")\n","        \"\"\"\n","def process_sequence_from_csv(seq_name, image_paths, output_dir, det_df):\n","    # ë§ˆì¹¨í‘œ ë¬¸ì œ ë°©ì§€ë¥¼ ìœ„í•´ ì•ˆì „í•œ ì‹œí€€ìŠ¤ëª… ì‚¬ìš©\n","    safe_seq_name = seq_name.replace('.', '_')\n","    os.makedirs(output_dir, exist_ok=True)\n","    video_path = os.path.join(output_dir, f\"{safe_seq_name}_risk_analysis.mp4\")\n","\n","    image_paths = sorted(image_paths)\n","    if not image_paths: return\n","\n","    # Init Tracker & Risk Manager\n","    tracker = Sort(max_age=5, min_hits=1, iou_threshold=0.3)\n","    risk_manager = IntentAwareRiskManager(window_size=10)\n","\n","    # Video Writer Init\n","    sample_img = cv2.imread(image_paths[0])\n","    h, w = sample_img.shape[:2]\n","    fps = 10.0\n","    out = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n","\n","    print(f\"ğŸ¬ Processing {safe_seq_name} from CSV...\")\n","\n","    # --- [ìˆ˜ì • í¬ì¸íŠ¸] ì‹œí€€ìŠ¤ ë°ì´í„° í•„í„°ë§ ---\n","    # Filenameì—ì„œ ì‹œí€€ìŠ¤ ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ì—¬ seq_nameê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸\n","    seq_data = det_df[det_df['Filename'].apply(lambda x: x.rsplit('_', 1)[0] == seq_name)].copy()\n","\n","    if seq_data.empty:\n","        print(f\"âš ï¸ Warning: No data found for {seq_name} in CSV.\")\n","        return\n","\n","    for frame_idx, img_path in enumerate(tqdm(image_paths, leave=False)):\n","        img_cv = cv2.imread(img_path)\n","        if img_cv is None: continue\n","\n","        frame_filename = os.path.basename(img_path)\n","        current_frame_dets = seq_data[seq_data['Filename'] == frame_filename].copy()\n","\n","        if 'conf' not in current_frame_dets.columns:\n","            current_frame_dets['conf'] = 1.0\n","        dets_to_sort = current_frame_dets[['x1', 'y1', 'x2', 'y2', 'conf']].values\n","\n","        track_dets = tracker.update(dets_to_sort)\n","\n","        if len(track_dets) > 0:\n","            for trk in track_dets:\n","                x1, y1, x2, y2, track_id = trk\n","                matched_iou_val = -1\n","                matched_row = None\n","                for _, det_row in current_frame_dets.iterrows():\n","                    iou_val = iou(trk[:4], det_row[['x1', 'y1', 'x2', 'y2']].values)\n","                    if iou_val > matched_iou_val and iou_val > 0.1:\n","                        matched_iou_val = iou_val\n","                        matched_row = det_row\n","\n","                if matched_row is not None:\n","                    loc_idx = int(matched_row['Location_ID'])\n","                    is_active = matched_row[['Brake', 'Left', 'Right', 'Hazard']].values.astype(int)\n","\n","                    risk_result = risk_manager.calculate_risk(\n","                        track_id=int(track_id),\n","                        bbox=[x1, y1, x2, y2],\n","                        location=loc_idx,\n","                        actions=is_active,\n","                        fps=fps, img_w=w, img_h=h\n","                    )\n","\n","                    level = risk_result[\"level\"]\n","                    color = RISK_COLORS.get(level, (0, 255, 0))\n","                    cv2.rectangle(img_cv, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n","\n","                    loc_names = [\"My\", \"Next\", \"Opposite\", \"RoadSide\", \"None\"]\n","                    info_text = f\"ID:{int(track_id)} | {loc_names[loc_idx] if loc_idx < 5 else '??'}\"\n","                    cv2.putText(img_cv, info_text, (int(x1), int(y1) - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n","                    cv2.putText(img_cv, f\"{level} ({risk_result['score']})\", (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n","                    if level != \"SAFE\":\n","                        cv2.putText(img_cv, risk_result[\"reason\"], (int(x1), int(y2) + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n","\n","        out.write(img_cv)\n","    out.release()\n","\n","# --- ì‹¤í–‰ ë¶€ë¶„ ---\n","# 1. CSV ë‚´ì˜ ì‹œí€€ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ (RSPLIT ê¸°ì¤€)\n","csv_sequence_names = all_det_df['Filename'].apply(lambda x: x.rsplit('_', 1)[0]).unique()\n","\n","print(f\"âœ… CSVì— í¬í•¨ëœ ì‹œí€€ìŠ¤ ëª©ë¡: {csv_sequence_names}\")\n","\n","for seq_name, img_list in sequences.items():\n","    # sequencesì˜ key(seq_name)ì— ë§ˆì¹¨í‘œê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ\n","    processed_seq_name = seq_name.replace('.', '_')\n","\n","    if processed_seq_name in csv_sequence_names:\n","        process_sequence_from_csv(\n","            processed_seq_name, # ë³€í™˜ëœ ì´ë¦„ì„ ì „ë‹¬\n","            img_list,\n","            OUTPUT_ROOT_RISK,\n","            all_det_df\n","        )\n","    else:\n","        print(f\"â© Skipping {processed_seq_name}: No matching data found in CSV.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":428},"id":"EnzWETobHUe0","executionInfo":{"status":"error","timestamp":1768462792912,"user_tz":-540,"elapsed":161,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}},"outputId":"14fea9f0-4ce2-4248-db26-dcf2c994d2e7"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ¬ Processing bb_1_140613_vehicle_224_55460.mp4_20260114 from CSV...\n"]},{"output_type":"error","ename":"ValueError","evalue":"invalid literal for int() with base 10: '143204.270'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-791342666.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m# --- ì‹¤í–‰ ë¶€ë¶„ ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     process_sequence_from_csv(\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mseq_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mimg_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3831078927.py\u001b[0m in \u001b[0;36mprocess_sequence_from_csv\u001b[0;34m(seq_name, image_paths, output_dir, det_df)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# NOTE: 'frame' ì»¬ëŸ¼ì´ ì—†ìœ¼ë¯€ë¡œ 'Filename'ì„ ê¸°ë°˜ìœ¼ë¡œ í•„í„°ë§í•˜ë„ë¡ ìˆ˜ì •\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mseq_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdet_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdet_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mseq_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mframe_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4922\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4923\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4924\u001b[0;31m         ).apply()\n\u001b[0m\u001b[1;32m   4925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4926\u001b[0m     def _reindex_indexer(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m         \u001b[0;31m# self.func is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0;31m#  Categorical (GH51645).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m         mapped = obj._map_values(\n\u001b[0m\u001b[1;32m   1508\u001b[0m             \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurried\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mna_action\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m         return lib.map_infer_mask(\n","\u001b[0;32mlib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3831078927.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# NOTE: 'frame' ì»¬ëŸ¼ì´ ì—†ìœ¼ë¯€ë¡œ 'Filename'ì„ ê¸°ë°˜ìœ¼ë¡œ í•„í„°ë§í•˜ë„ë¡ ìˆ˜ì •\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mseq_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdet_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdet_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mseq_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mframe_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '143204.270'"]}]},{"cell_type":"code","source":["import pandas as pd\n","import cv2\n","import os\n","import numpy as np\n","from tqdm import tqdm\n","import importlib\n","\n","# Sort íŠ¸ë˜ì»¤ì—ì„œ iou í•¨ìˆ˜ ë¡œë“œ\n","import sort_tracker\n","importlib.reload(sort_tracker)\n","from sort_tracker import Sort, iou\n","\n","# 1. ê²½ë¡œ ì„¤ì •\n","# [ìˆ˜ì • í¬ì¸íŠ¸] ì´ì „ ë‹¨ê³„ì—ì„œ ìƒì„±ëœ CSV íŒŒì¼ì˜ ì •í™•í•œ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n","DET_CSV_PATH = \"/content/sago_SafeDrive_T4_HighPerf/test_sequences_combined/bb_1_211026_vehicle_144_301_mp4/bb_1_211026_vehicle_144_301_mp4_analysis.csv\"\n","OUTPUT_ROOT_RISK = \"/content/sago_SafeDrive_T4_HighPerf/risk_video\"\n","\n","all_det_df = pd.read_csv(DET_CSV_PATH)\n","\n","# ìœ„í—˜ë„ ìƒ‰ìƒ ì •ì˜\n","RISK_COLORS = {\n","    \"SAFE\": (0, 255, 0),       # Green\n","    \"WARNING\": (0, 165, 255),  # Orange\n","    \"DANGER\": (0, 0, 255),     # Red\n","    \"CAUTION\": (0, 255, 255)   # Yellow\n","}\n","\n","# 2. í•µì‹¬ ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\n","def process_sequence_from_csv(seq_name, image_paths, output_dir, det_df):\n","    # ë§ˆì¹¨í‘œ ë¬¸ì œ ë°©ì§€ë¥¼ ìœ„í•´ ì•ˆì „í•œ ì‹œí€€ìŠ¤ëª… ì‚¬ìš©\n","    safe_seq_name = seq_name.replace('.', '_')\n","    os.makedirs(output_dir, exist_ok=True)\n","    video_path = os.path.join(output_dir, f\"{safe_seq_name}_risk_analysis.mp4\")\n","\n","    image_paths = sorted(image_paths)\n","    if not image_paths: return\n","\n","    # Init Tracker & Risk Manager (IntentAwareRiskManagerê°€ ë©”ëª¨ë¦¬ì— ìˆì–´ì•¼ í•¨)\n","    tracker = Sort(max_age=5, min_hits=1, iou_threshold=0.3)\n","    risk_manager = IntentAwareRiskManager(window_size=10)\n","\n","    # Video Writer Init\n","    sample_img = cv2.imread(image_paths[0])\n","    h, w = sample_img.shape[:2]\n","    fps = 10.0\n","    out = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n","\n","    print(f\"ğŸ¬ Processing {safe_seq_name} from CSV...\")\n","\n","    # ì‹œí€€ìŠ¤ ë°ì´í„° í•„í„°ë§ (íŒŒì¼ëª… ê·œì¹™ì— ë§ì¶¤)\n","    seq_data = det_df[det_df['Filename'].apply(lambda x: x.rsplit('_', 1)[0] == seq_name)].copy()\n","\n","    if seq_data.empty:\n","        print(f\"âš ï¸ Warning: No data found for {seq_name} in CSV.\")\n","        return\n","\n","    for frame_idx, img_path in enumerate(tqdm(image_paths, leave=False)):\n","        img_cv = cv2.imread(img_path)\n","        if img_cv is None: continue\n","\n","        frame_filename = os.path.basename(img_path)\n","        current_frame_dets = seq_data[seq_data['Filename'] == frame_filename].copy()\n","\n","        # SORT ì…ë ¥ì„ ìœ„í•œ ë°ì´í„° ì •ì œ\n","        if 'conf' not in current_frame_dets.columns:\n","            current_frame_dets['conf'] = 1.0\n","        dets_to_sort = current_frame_dets[['x1', 'y1', 'x2', 'y2', 'conf']].values\n","\n","        # 1. íŠ¸ë˜í‚¹ ì—…ë°ì´íŠ¸\n","        track_dets = tracker.update(dets_to_sort)\n","\n","        if len(track_dets) > 0:\n","            for trk in track_dets:\n","                x1, y1, x2, y2, track_id = trk\n","\n","                # 2. CSV ì›ë³¸ ë°ì´í„°ì™€ IoU ë§¤ì¹­ (Location_ID, Action ì •ë³´ íšë“)\n","                matched_iou_val = -1\n","                matched_row = None\n","                for _, det_row in current_frame_dets.iterrows():\n","                    iou_val = iou(trk[:4], det_row[['x1', 'y1', 'x2', 'y2']].values)\n","                    if iou_val > matched_iou_val and iou_val > 0.1:\n","                        matched_iou_val = iou_val\n","                        matched_row = det_row\n","\n","                if matched_row is not None:\n","                    loc_idx = int(matched_row['Location_ID'])\n","                    is_active = matched_row[['Brake', 'Left', 'Right', 'Hazard']].values.astype(int)\n","\n","                    # 3. ìœ„í—˜ë„ ê³„ì‚°\n","                    risk_result = risk_manager.calculate_risk(\n","                        track_id=int(track_id),\n","                        bbox=[x1, y1, x2, y2],\n","                        location=loc_idx,\n","                        actions=is_active,\n","                        fps=fps, img_w=w, img_h=h\n","                    )\n","\n","                    # 4. ì‹œê°í™”\n","                    level = risk_result[\"level\"]\n","                    color = RISK_COLORS.get(level, (0, 255, 0))\n","                    cv2.rectangle(img_cv, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n","\n","                    loc_names = [\"My\", \"Next\", \"Opposite\", \"RoadSide\", \"None\"]\n","                    info_text = f\"ID:{int(track_id)} | {loc_names[loc_idx] if loc_idx < 5 else '??'}\"\n","                    cv2.putText(img_cv, info_text, (int(x1), int(y1) - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n","                    cv2.putText(img_cv, f\"{level} ({risk_result['score']})\", (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n","\n","                    if level != \"SAFE\":\n","                        cv2.putText(img_cv, risk_result[\"reason\"], (int(x1), int(y2) + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n","\n","        out.write(img_cv)\n","    out.release()\n","\n","\"\"\"\n","# 3. ì‹¤í–‰ ë¶€ë¶„\n","csv_sequence_names = all_det_df['Filename'].apply(lambda x: x.rsplit('_', 1)[0]).unique()\n","print(f\"âœ… CSVì— í¬í•¨ëœ ì‹œí€€ìŠ¤ ëª©ë¡: {csv_sequence_names}\")\n","\n","for seq_name, img_list in sequences.items():\n","    processed_seq_name = seq_name.replace('.', '_')\n","\n","    if processed_seq_name in csv_sequence_names:\n","        process_sequence_from_csv(\n","            processed_seq_name,\n","            img_list,\n","            OUTPUT_ROOT_RISK,\n","            all_det_df\n","        )\n","    else:\n","        print(f\"â© Skipping {processed_seq_name}: No matching data found in CSV.\")\n","\n","print(f\"\\nâœ¨ ìœ„í—˜ë„ ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ê²½ë¡œ: {OUTPUT_ROOT_RISK}\")\n","\"\"\"\n","# --- 3. ì‹¤í–‰ ë¶€ë¶„ (ìˆ˜ì • ë²„ì „) ---\n","\n","# CSV ë‚´ì˜ ì‹œí€€ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ\n","csv_sequence_names = all_det_df['Filename'].apply(lambda x: x.rsplit('_', 1)[0]).unique()\n","print(f\"âœ… CSVì— í¬í•¨ëœ ì‹œí€€ìŠ¤ ëª©ë¡: {csv_sequence_names}\")\n","\n","for seq_name, img_list in sequences.items():\n","    # ì–µì§€ë¡œ ì´ë¦„ì„ ë³€í™˜í•˜ì§€ ì•Šê³ ,\n","    # 1. ì›ë³¸ ì´ë¦„(seq_name)ì´ ìˆëŠ”ì§€ í™•ì¸\n","    # 2. í˜¹ì€ ë§ˆì¹¨í‘œë¥¼ ë³€í™˜í•œ ì´ë¦„ì´ ìˆëŠ”ì§€ í™•ì¸\n","    processed_seq_name = seq_name.replace('.', '_')\n","\n","    target_name = None\n","    if seq_name in csv_sequence_names:\n","        target_name = seq_name\n","    elif processed_seq_name in csv_sequence_names:\n","        target_name = processed_seq_name\n","\n","    if target_name:\n","        process_sequence_from_csv(\n","            target_name,\n","            img_list,\n","            OUTPUT_ROOT_RISK,\n","            all_det_df\n","        )\n","    else:\n","        print(f\"â© Skipping {seq_name}: No matching data found in CSV.\")\n","\n","print(f\"\\nâœ¨ ìœ„í—˜ë„ ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ê²½ë¡œ: {OUTPUT_ROOT_RISK}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-2UZ7xgEmgSG","executionInfo":{"status":"ok","timestamp":1768465185816,"user_tz":-540,"elapsed":3535,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}},"outputId":"4a8b7096-0a8e-4d99-c391-dbafe9e43f93"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… CSVì— í¬í•¨ëœ ì‹œí€€ìŠ¤ ëª©ë¡: ['bb_1_211026_vehicle_144_301.mp4']\n","â© Skipping bb_1_210701_vehicle_217_21650.mp4: No matching data found in CSV.\n","â© Skipping bb_1_160612_vehicle_212_53256.mp4: No matching data found in CSV.\n","â© Skipping bb_1_141024_vehicle_46_180.mp4: No matching data found in CSV.\n","ğŸ¬ Processing bb_1_211026_vehicle_144_301_mp4 from CSV...\n"]},{"output_type":"stream","name":"stderr","text":["                                               "]},{"output_type":"stream","name":"stdout","text":["â© Skipping bb_1_170304_vehicle_114_075.mp4: No matching data found in CSV.\n","â© Skipping bb_1_150402_vehicle_142_073.mp4: No matching data found in CSV.\n","â© Skipping bb_1_181121_vehicle_117_045.mp4: No matching data found in CSV.\n","â© Skipping bb_1_200714_vehicle_200_28840.mp4: No matching data found in CSV.\n","â© Skipping bb_1_210414_vehicle_244_50609.mp4: No matching data found in CSV.\n","â© Skipping bb_1_210114_vehicle_253_50073.mp4: No matching data found in CSV.\n","â© Skipping bb_1_210522_vehicle_315_061.mp4: No matching data found in CSV.\n","\n","âœ¨ ìœ„í—˜ë„ ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ê²½ë¡œ: /content/sago_SafeDrive_T4_HighPerf/risk_video\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}]},{"cell_type":"markdown","source":["íŠ¹ì • íŒŒì¼ë§Œ ì €ì¥í•˜ë„ë¡ ì„¤ì • (ì´ë¯¸ì§€)"],"metadata":{"id":"Ah0KaK2wO9EZ"}},{"cell_type":"code","source":["import pandas as pd\n","import cv2\n","import os\n","import numpy as np\n","from tqdm import tqdm\n","\n","# Sort íŠ¸ë˜ì»¤ì—ì„œ iou í•¨ìˆ˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n","import importlib\n","import sort_tracker\n","importlib.reload(sort_tracker) # Reload the module to ensure latest changes are applied\n","from sort_tracker import Sort, iou\n","\n","# 1. ë¨¼ì € CSV íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤. (ê²½ë¡œëŠ” ë³¸ì¸ì˜ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)\n","DET_CSV_PATH = \"/content/SafeDrive_T4_HighPerf2/test_sequences_combined/Yeonhwi/Yeonhwi_combined.csv\"\n","all_det_df = pd.read_csv(DET_CSV_PATH)\n","\n","# OUTPUT_ROOT_RISK ë³€ìˆ˜ ì •ì˜ ì¶”ê°€\n","OUTPUT_ROOT_RISK = \"/content/SafeDrive_T4_HighPerf2/integrated_risk_images\"\n","\n","# RISK_COLORS ì •ì˜ ì¶”ê°€ (ì´ì „ ì…€ì—ì„œ ì •ì˜ë˜ì—ˆìœ¼ë‚˜ ëª…í™•ì„±ì„ ìœ„í•´ ì¶”ê°€)\n","RISK_COLORS = {\n","    \"SAFE\": (0, 255, 0),       # Green\n","    \"WARNING\": (0, 165, 255),  # Orange\n","    \"DANGER\": (0, 0, 255),\n","    \"CAUTION\": (0, 255, 255) # Yellow\n","}\n","\n","import pandas as pd\n","import cv2\n","import os\n","import numpy as np\n","from tqdm import tqdm\n","\n","# --- ìˆ˜ì • í¬ì¸íŠ¸: VideoWriter ëŒ€ì‹  í´ë” ìƒì„± ë° imwrite ì‚¬ìš© ---\n","\n","def process_sequence_from_csv_to_images(seq_name, image_paths, output_root, det_df):\n","    # ì‹œí€€ìŠ¤ë³„ë¡œ í•˜ìœ„ í´ë” ìƒì„± (ì˜ˆ: .../integrated_risk_videos2/CounterClock2_Fog/)\n","    seq_output_dir = os.path.join(output_root, seq_name)\n","    os.makedirs(seq_output_dir, exist_ok=True)\n","\n","    image_paths = sorted(image_paths)\n","    if not image_paths: return\n","\n","    # Init Tracker & Risk Manager\n","    tracker = Sort(max_age=5, min_hits=1, iou_threshold=0.3)\n","    risk_manager = IntentAwareRiskManager(window_size=10)\n","\n","    print(f\"ğŸ“¸ Processing {seq_name} (Saving as Images)...\")\n","\n","    # ë°ì´í„° í•„í„°ë§ ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼)\n","    seq_data = det_df[det_df['Filename'].apply(lambda x: x.startswith(seq_name))].copy()\n","\n","    for frame_idx, img_path in enumerate(tqdm(image_paths, leave=False)):\n","        img_cv = cv2.imread(img_path)\n","        if img_cv is None: continue\n","        h, w = img_cv.shape[:2]\n","\n","        # CSV ë°ì´í„° ì¶”ì¶œ\n","        frame_filename = os.path.basename(img_path)\n","        current_frame_dets = seq_data[seq_data['Filename'] == frame_filename].copy()\n","\n","        if 'conf' not in current_frame_dets.columns:\n","            current_frame_dets['conf'] = 1.0\n","        dets_to_sort = current_frame_dets[['x1', 'y1', 'x2', 'y2', 'conf']].values\n","\n","        # SORT Tracking\n","        track_dets = tracker.update(dets_to_sort)\n","\n","        # ìœ„í—˜ë„ ê³„ì‚° ë° ë“œë¡œì‰\n","        if len(track_dets) > 0:\n","            for trk in track_dets:\n","                x1, y1, x2, y2, track_id = trk\n","\n","                # IoU ë§¤ì¹­ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)\n","                matched_iou_val = -1\n","                matched_row = None\n","                for _, det_row in current_frame_dets.iterrows():\n","                    iou_val = iou(trk[:4], det_row[['x1', 'y1', 'x2', 'y2']].values)\n","                    if iou_val > matched_iou_val and iou_val > 0.1:\n","                        matched_iou_val = iou_val\n","                        matched_row = det_row\n","\n","                if matched_row is not None:\n","                    loc_idx = int(matched_row['Location_ID'])\n","                    is_active = matched_row[['Brake', 'Left', 'Right', 'Hazard']].values.astype(int)\n","\n","                    risk_result = risk_manager.calculate_risk(\n","                        track_id=int(track_id),\n","                        bbox=[x1, y1, x2, y2],\n","                        location=loc_idx,\n","                        actions=is_active,\n","                        fps=10.0, img_w=w, img_h=h\n","                    )\n","\n","                    # ì‹œê°í™” ë¶€ë¶„\n","                    level = risk_result[\"level\"]\n","                    color = RISK_COLORS.get(level, (0, 255, 0))\n","                    cv2.rectangle(img_cv, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n","\n","                    loc_names = [\"My\", \"Next\", \"Opposite\", \"RoadSide\", \"None\"]\n","                    info_text = f\"ID:{int(track_id)} | {loc_names[loc_idx] if loc_idx < 5 else '??'}\"\n","                    cv2.putText(img_cv, info_text, (int(x1), int(y1) - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n","                    cv2.putText(img_cv, f\"{level} ({risk_result['score']})\", (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n","                    if level != \"SAFE\":\n","                        cv2.putText(img_cv, risk_result[\"reason\"], (int(x1), int(y2) + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n","\n","        # --- [ë³€ê²½ íŒŒíŠ¸: ì˜ìƒ ì €ì¥ ëŒ€ì‹  ì´ë¯¸ì§€ ì €ì¥] ---\n","        # ì›ë³¸ íŒŒì¼ëª… ì•ì— 'risk_'ë¥¼ ë¶™ì—¬ ì €ì¥í•˜ê±°ë‚˜ í”„ë ˆì„ ë²ˆí˜¸ë¡œ ì €ì¥\n","        save_filename = f\"risk_{frame_filename}\"\n","        save_path = os.path.join(seq_output_dir, save_filename)\n","        cv2.imwrite(save_path, img_cv)\n","\n","\"\"\"\n","# --- ì‹¤í–‰ ë¶€ë¶„ ---\n","for seq_name, img_list in sequences.items():\n","    process_sequence_from_csv_to_images(\n","        seq_name,\n","        img_list,\n","        OUTPUT_ROOT_RISK,\n","        all_det_df\n","    )\n","\"\"\"\n","\n","# --- ì‹¤í–‰ ë¶€ë¶„ ---\n","\n","# 1. CSV íŒŒì¼ ì•ˆì— ì–´ë–¤ ì‹œí€€ìŠ¤ ì´ë¦„ë“¤ì´ ìˆëŠ”ì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n","# Filename ì»¬ëŸ¼ì˜ ê°’(ì˜ˆ: 'CounterClock2_Fog_001.png')ì—ì„œ ì‹œí€€ìŠ¤ ì´ë¦„ë§Œ ë½‘ì•„ëƒ…ë‹ˆë‹¤.\n","csv_sequence_names = all_det_df['Filename'].apply(lambda x: x.rsplit('_', 1)[0]).unique()\n","\n","print(f\"âœ… CSVì— í¬í•¨ëœ ì‹œí€€ìŠ¤ ëª©ë¡: {csv_sequence_names}\")\n","\n","for seq_name, img_list in sequences.items():\n","    # 2. í˜„ì¬ ì²˜ë¦¬í•˜ë ¤ëŠ” í´ë”ëª…(seq_name)ì´ CSV ë¦¬ìŠ¤íŠ¸ì— ë“¤ì–´ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n","    if seq_name in csv_sequence_names:\n","        process_sequence_from_csv_to_images(\n","            seq_name,\n","            img_list,\n","            OUTPUT_ROOT_RISK,\n","            all_det_df\n","        )\n","    else:\n","        # CSVì— ì •ë³´ê°€ ì—†ëŠ” í´ë”ëŠ” ê·¸ëƒ¥ ê±´ë„ˆëœë‹ˆë‹¤.\n","        print(f\"â© Skipping {seq_name}: No matching data found in CSV.\")\n","\n","    #out.write(img_cv)\n","\n","   # out.release()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"06tRgIO9OpY6","executionInfo":{"status":"ok","timestamp":1768460577215,"user_tz":-540,"elapsed":30834,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}},"outputId":"e898ab6b-50b4-4ca1-ce9d-7eb967ce3540"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… CSVì— í¬í•¨ëœ ì‹œí€€ìŠ¤ ëª©ë¡: ['Yeonhwi']\n","ğŸ“¸ Processing Yeonhwi (Saving as Images)...\n"]},{"output_type":"stream","name":"stderr","text":["                                                 "]},{"output_type":"stream","name":"stdout","text":["â© Skipping CounterClock2_Fog: No matching data found in CSV.\n","â© Skipping ETRINear_Fog: No matching data found in CSV.\n","â© Skipping OisamtoBanseok_Snow: No matching data found in CSV.\n","â© Skipping RAIN_Noeun: No matching data found in CSV.\n","â© Skipping TailLight27: No matching data found in CSV.\n","â© Skipping TailLight57: No matching data found in CSV.\n","â© Skipping TailLight87: No matching data found in CSV.\n","â© Skipping TailLight45: No matching data found in CSV.\n","â© Skipping TailLight04: No matching data found in CSV.\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}]},{"cell_type":"markdown","source":["ì˜ìƒ íŒŒì¼ ë“œë¼ì´ë¸Œë¡œ ë³µì‚¬"],"metadata":{"id":"PhpnkM2e_yl9"}},{"cell_type":"code","source":["# -r (recursive): í•˜ìœ„ í´ë” í¬í•¨ ì „ì²´ ë³µì‚¬\n","!cp -r \"/content/sago_SafeDrive_T4_HighPerf/risk_video\" \"/content/drive/MyDrive/OD_project/sago\""],"metadata":{"id":"fY_IMzL0JnoU","executionInfo":{"status":"ok","timestamp":1768465231826,"user_tz":-540,"elapsed":307,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}}},"execution_count":112,"outputs":[]},{"cell_type":"markdown","source":["ì´ë¯¸ì§€ íŒŒì¼ ë“œë¼ì´ë¸Œë¡œ ë³µì‚¬"],"metadata":{"id":"1pGRRLgONglU"}},{"cell_type":"code","source":["# -r (recursive): í•˜ìœ„ í´ë” í¬í•¨ ì „ì²´ ë³µì‚¬\n","!cp -r \"/content/SafeDrive_T4_HighPerf2/integrated_risk_images\" \"/content/drive/MyDrive/OD_project/risk_results_images2/\""],"metadata":{"id":"ToYYO4dJIZVz","executionInfo":{"status":"ok","timestamp":1768460669726,"user_tz":-540,"elapsed":53368,"user":{"displayName":"Minji Kim","userId":"08624505677748081372"}}},"execution_count":80,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tOs_6i1rIZYY"},"execution_count":null,"outputs":[]}]}